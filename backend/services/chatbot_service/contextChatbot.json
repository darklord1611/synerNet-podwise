{
    "context_chatbot": [
        {
            "start": 2752,
            "context": "There is generally a feeling like this AI system has an outward looking, like the way you are, like sitting with a good friend, looking up at the stars, like asking pothead like questions about the universe wondering what it's all about the curiosity you talk about there There's a sense no matter how mundane the question I ask it There's a sense of cosmic grandeur to the whole thing. Well, we are actually working hard to have engineering, math, physics answers that you can count on. So for the other sort of AIs out there, the so-called large language models, I've not found the engineering to be reliable and the hallucination, it unfortunately hallucinates most when you least want it to hallucinate. Yeah. So when you ask important difficult questions, that's when it tends to be confidently wrong. So we're really trying hard to say, okay, how do we be as grounded as possible so you can count on the results. Trace things back to physics first principles, mathematical logic. So underlying the humor is an aspiration to adhere to the truth of the universe as closely as possible. That's really tricky. ",
            "score": 0.6126552820205688
        },
        {
            "start": 6051,
            "context": "Oh, so a lot of that, I got the sense, so a lot of the X algorithm has been open source and been written up about, and it seems there to be some machine learning, it's disparate, but there's some machine learning. There's a little bit. But it needs to be entirely that. Like if you explicitly follow someone, that's 1 thing. But if you, in terms of what is recommended from people that you don't follow, That should all be AI. I mean, it's a fascinating problem. Yeah. So there's several aspects of this fascinating. First, as the write-up goes, it first picks 1, 500 tweets from a pool of hundreds of millions. First of all, that's fascinating because you have hundreds of millions of posts every single day and it has to pick 1500 from which it then does obviously people you follow but then there's also like some kind of clustering it has to do to figure out what kind of human are you what kind of new clusters might be relevant to you people like you this this kind of this kind of problem is just fascinating because it has to then rank those 1500 with some filtering and then recommend you just a handful. ",
            "score": 0.5190251469612122
        },
        {
            "start": 8043,
            "context": "old friend, Tesla Autopilot, and it's probably 1 of the most intelligent real-world AI systems in the world. Right, you followed it from the beginning. Yeah, it was 1 of the most incredible robots in the world and continues to be. And it was really exciting. And it was super exciting when it generalized, became more than a robot on 4 wheels, but a real world AI system that perceives the world. Yeah. And can have potentially different embodiments. Well, I mean, the really wild thing about the end-to-end training is that it like, it learns to read, like you can read signs, but we never taught it to read. So, yeah, we never taught it what a car was or what a person was or a bicyclist. It learnt what all those things are, what all the objects are on the road from video, just from watching video, just like humans. I mean, humans are photons and control controls out. Like the vast majority of information reaching our brain is from our eyes. And you say, well, what's the output? The output is our motor signals to our fingers and mouth in order to communicate. Photons in, controls out. The same is true of the car. But by looking at the sequence of images, it's, you've agreed with Ilyas Iskova recently where he talked about LLM forming a world model and basically language is a projection of that wall model onto a sequence of letters. It finds ",
            "score": 0.48780661821365356
        }
    ]
}