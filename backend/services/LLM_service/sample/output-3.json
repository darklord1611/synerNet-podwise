{"utterances": [{"speaker": 0, "transcript": [{"text": "The following is a conversation with Elon Musk, his fourth time on this, the Lex Friedman podcast.", "chunk": 0}, {"text": "I thought you were going", "chunk": 0}], "start": 20.5, "end": 21.16}, {"speaker": 1, "transcript": [{"text": "to finish it.", "chunk": 0}, {"text": "I thought you were", "chunk": 0}], "start": 21.205, "end": 21.265}, {"speaker": 0, "transcript": [{"text": "gonna finish it.", "chunk": 0}, {"text": "It's 1 of the greatest themes in all film history.", "chunk": 0}], "start": 25.599998, "end": 28.2}, {"speaker": 1, "transcript": [{"text": "Yeah, it was great.", "chunk": 0}], "start": 31.42, "end": 32.36}, {"speaker": 0, "transcript": [{"text": "So I was just thinking about the Roman Empire, as 1 does.", "chunk": 0}], "start": 33.74, "end": 36.98}, {"speaker": 1, "transcript": [{"text": "There's that whole meme where, oh guys, I'm thinking about the Roman Empire at least once", "chunk": 0}], "start": 38.559998, "end": 44.34}, {"speaker": 0, "transcript": [{"text": "a day.", "chunk": 0}, {"text": "And half the population is confused whether it's true or not.", "chunk": 0}, {"text": "But more seriously, thinking about the wars going on in the world today, and as you know, war and military conquest has been a big part of Roman society and culture, and I think has been a big part of most empires and dynasties throughout human history.", "chunk": 0}], "start": 47.9, "end": 65.88}, {"speaker": 1, "transcript": [{"text": "So.", "chunk": 0}, {"text": "Yeah, they usually came as a result of conquest.", "chunk": 0}, {"text": "I mean, there's some like the Austro-Hungarian Empire where there was just a lot of sort of clever marriages.", "chunk": 0}], "start": 71.02, "end": 75.479996}, {"speaker": 0, "transcript": [{"text": "But fundamentally, there's an engine of conquest.", "chunk": 0}, {"text": "Yeah.", "chunk": 0}, {"text": "And they celebrate excellence.", "chunk": 0}, {"text": "In warfare, Many of the leaders were excellent generals, that kind of thing.", "chunk": 0}, {"text": "So big picture question, Grok approved.", "chunk": 0}], "start": 88.16, "end": 91.06}, {"speaker": 0, "transcript": [{"text": "I asked this is a good question to ask.", "chunk": 0}], "start": 91.06, "end": 92.9}, {"speaker": 1, "transcript": [{"text": "Get tested, Grok approved?", "chunk": 0}], "start": 92.9, "end": 94.12}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 0}, {"text": "At least on fun mode.", "chunk": 0}, {"text": "To what degree do you think war is part of human nature versus a consequence of how human societies are structured.", "chunk": 0}, {"text": "I ask this as you have somehow controversially been a proponent of peace.", "chunk": 0}], "start": 110.8, "end": 116.72}, {"speaker": 1, "transcript": [{"text": "I'm generally a proponent of peace.", "chunk": 0}, {"text": "I mean, ignorance is perhaps in my view, the real enemy to counter it.", "chunk": 0}, {"text": "That's the real hard part, not fighting other humans.", "chunk": 0}, {"text": "But all creatures fight.", "chunk": 0}, {"text": "I mean, the jungle is a, you look at the, you'll think of nature as perhaps some sort of peaceful thing, but in fact it is not.", "chunk": 0}], "start": 130.26, "end": 138.38}, {"speaker": 1, "transcript": [{"text": "There's some quite funny, when a hoods hog thing, where he's like in the jungle, like saying that it's like basically just murder and death in every direction.", "chunk": 0}, {"text": "I mean, the plants and animals in the jungle are constantly trying to kill each other every single day, every minute.", "chunk": 0}, {"text": "So it's not like, you know, we're unusual in that respect.", "chunk": 0}], "start": 156.18, "end": 160.32}, {"speaker": 0, "transcript": [{"text": "There's a relevant question here whether with greater intelligence comes greater control over these base instincts for violence?", "chunk": 0}], "start": 160.51001, "end": 168.12}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 0}, {"text": "We have much more of an ability to control our limbic instinct for violence than say a chimpanzee.", "chunk": 0}, {"text": "And in fact, If 1 looks at say chimpanzee society, it is not friendly.", "chunk": 0}, {"text": "I mean, the bonobos are an exception, but chimpanzee society is full of violence and it's quite horrific, frankly.", "chunk": 0}, {"text": "That's our limbic system in action.", "chunk": 0}], "start": 196.1, "end": 197.76}, {"speaker": 1, "transcript": [{"text": "Like you don't want to be on the wrong side of a chimpanzee.", "chunk": 0}, {"text": "It'll eat your face off and tear your nuts off.", "chunk": 0}], "start": 200.26, "end": 202.16}, {"speaker": 0, "transcript": [{"text": "Yeah, basically there's no limits or ethics or, the Romans had just war.", "chunk": 0}, {"text": "There's no just war in chimpanzee societies.", "chunk": 0}, {"text": "Is war and dominance by any means necessary?", "chunk": 0}], "start": 209.92, "end": 213.02}, {"speaker": 1, "transcript": [{"text": "Yeah, chimpanzee society is like a primitive version of human society.", "chunk": 0}, {"text": "It's not like peace loving basically, at all.", "chunk": 0}, {"text": "There's extreme violence.", "chunk": 0}, {"text": "And then once in a while, somebody who's watched too many Disney movies decides to raise a Chopin's E as a pad.", "chunk": 0}, {"text": "And then that eats their face or rips their nuts off or chews their fingers off.", "chunk": 0}], "start": 231.52, "end": 234.92}, {"speaker": 1, "transcript": [{"text": "That kind of thing.", "chunk": 0}, {"text": "Yeah, it's happened several times.", "chunk": 0}], "start": 236.24, "end": 237.66}, {"speaker": 0, "transcript": [{"text": "Ripping your nuts off is an interesting strategy for interaction.", "chunk": 0}], "start": 237.88, "end": 241.42}, {"speaker": 1, "transcript": [{"text": "So it's happened to people, it's unfortunate.", "chunk": 0}, {"text": "That's I guess 1 way to ensure that the other chump doesn't contribute to the gene pool.", "chunk": 0}], "start": 244.36, "end": 250.68}, {"speaker": 0, "transcript": [{"text": "Well, from a martial arts perspective, it's a fascinating strategy.", "chunk": 0}], "start": 250.8, "end": 253.6}, {"speaker": 1, "transcript": [{"text": "And the nut-ripper.", "chunk": 0}], "start": 253.86, "end": 255.94}, {"speaker": 0, "transcript": [{"text": "I wonder which of the martial arts teaches that.", "chunk": 0}], "start": 258.66, "end": 261.0}, {"speaker": 1, "transcript": [{"text": "I think it's safe to say if somebody's got your nuts in their hands and has the option of rubbing them off, you will be amenable to whatever they want.", "chunk": 0}, {"text": "Yeah.", "chunk": 1}], "start": 270.06, "end": 270.56}, {"speaker": 0, "transcript": [{"text": "So like I said, somehow controversially, you've been a proponent of peace on Twitter on X.", "chunk": 1}, {"text": "Yeah.", "chunk": 1}, {"text": "So let me ask you about the wars going on today and to see what the path to peace could be.", "chunk": 1}, {"text": "How do you hope the current war in Israel and Gaza comes to an end?", "chunk": 1}, {"text": "What path do you see that can minimize human suffering in the long term in that part of the world?", "chunk": 1}], "start": 288.26, "end": 294.3}, {"speaker": 1, "transcript": [{"text": "Well, I think that part of the world is definitely, like if you look up the, there is no easy answer in the dictionary.", "chunk": 1}, {"text": "It'll be like the picture of the Middle East, in Israel especially.", "chunk": 1}, {"text": "So there is no easy answer.", "chunk": 1}, {"text": "This is strictly my opinion is that the goal of Hamas was to provoke an overreaction from Israel.", "chunk": 1}, {"text": "They obviously did not expect to have a military victory, but they really wanted to commit the worst atrocities that they could in order to provoke the most aggressive response possible from Israel.", "chunk": 1}], "start": 324.66, "end": 340.62}, {"speaker": 1, "transcript": [{"text": "And then leverage that aggressive response to rally Muslims worldwide for the cause of Gaza and Palestine, which they have succeeded in doing.", "chunk": 1}, {"text": "So the counterintuitive thing here, I think that the thing that I think should be done, even though it is very difficult, is that I would recommend that Israel engage in the most conspicuous acts of kindness possible, every part, everything.", "chunk": 1}, {"text": "That is the actual thing that would thwart the goal of Hamas.", "chunk": 1}], "start": 376.02, "end": 378.98}, {"speaker": 0, "transcript": [{"text": "So in some sense, the degree that makes sense in geopolitics, turn the other cheek, implemented.", "chunk": 1}], "start": 379.66, "end": 385.12}, {"speaker": 1, "transcript": [{"text": "It's not exactly turn the other cheek, because I do think that there's, you know, I think it is appropriate for Israel to find the Hamas members and, you know, either kill them or cost rate them.", "chunk": 1}, {"text": "Like that's something that has to be done because they're just going to keep, keep, keep coming.", "chunk": 1}, {"text": "Otherwise.", "chunk": 1}, {"text": "But in addition to that, they need to do whatever they can.", "chunk": 1}, {"text": "There's some talk of establishing, for example, a mobile hospital.", "chunk": 1}], "start": 418.32, "end": 421.82}, {"speaker": 1, "transcript": [{"text": "I'd recommend doing that.", "chunk": 1}, {"text": "Just making sure that there's food, water, medical necessities, and just be over the top about it and be very transparent.", "chunk": 1}, {"text": "So that you can't claim it's a trick.", "chunk": 1}, {"text": "Like just put a webcam on the thing, you know, all 24 7.", "chunk": 1}], "start": 443.35, "end": 447.98}, {"speaker": 0, "transcript": [{"text": "Deploy acts of kindness.", "chunk": 1}], "start": 449.1, "end": 450.54}, {"speaker": 1, "transcript": [{"text": "Yeah, conspicuous acts of kindness that that with that are unequivocal meaning they can't be somehow because her muscle then their response will be oh it's a trick.", "chunk": 1}, {"text": "Therefore you have to counter how how is not a trick.", "chunk": 1}], "start": 463.54, "end": 466.24}, {"speaker": 0, "transcript": [{"text": "This ultimately fights the broader force of hatred in the region.", "chunk": 1}], "start": 467.08, "end": 471.08}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 1}, {"text": "I'm not sure who said it, it's a pretty apocryphal saying, but an eye for an eye makes everyone blind.", "chunk": 1}, {"text": "Now that neck of the woods, they really believe in the whole eye for an eye thing.", "chunk": 1}, {"text": "But you really have, if you're not going to just outright commit genocide, like against an entire people, which obviously would not be acceptable to, really shouldn't be acceptable to anyone, then you're gonna leave basically a lot of people alive who subsequently hate Israel.", "chunk": 1}, {"text": "So really the question is like, how, for every Hamas member that you kill, how many did you create?", "chunk": 1}], "start": 505.24, "end": 511.56}, {"speaker": 1, "transcript": [{"text": "And if you create more than you killed, you've not succeeded.", "chunk": 1}, {"text": "That's the real situation there.", "chunk": 1}, {"text": "And it's safe to say that If you kill somebody's child in Gaza, you've made at least a few homeless members who will die just to kill an Israeli.", "chunk": 1}, {"text": "That's the situation.", "chunk": 1}, {"text": "So, but I mean, this is 1 of the most contentious subjects 1 could possibly discuss.", "chunk": 1}], "start": 545.08, "end": 552.74}, {"speaker": 1, "transcript": [{"text": "But I think if the goal ultimately is some sort of long-term peace, 1 has to look at this from the standpoint of over time, are there more or fewer terrorists being created?", "chunk": 1}], "start": 553.06, "end": 565.8}, {"speaker": 0, "transcript": [{"text": "Let me just linger on war.", "chunk": 1}, {"text": "Yeah, war, it would", "chunk": 1}], "start": 569.24, "end": 570.42}, {"speaker": 1, "transcript": [{"text": "safe say wars always existed and always will exist.", "chunk": 1}], "start": 570.42, "end": 573.12}, {"speaker": 0, "transcript": [{"text": "Always will exist.", "chunk": 1}], "start": 573.32, "end": 574.44}, {"speaker": 1, "transcript": [{"text": "Always has existed and always will exist.", "chunk": 1}], "start": 575.2, "end": 577.22}, {"speaker": 0, "transcript": [{"text": "I hope not.", "chunk": 1}, {"text": "You think it", "chunk": 1}], "start": 578.7, "end": 579.08}, {"speaker": 1, "transcript": [{"text": "always will?", "chunk": 1}, {"text": "There will always be war.", "chunk": 1}, {"text": "It's a question of just how much war and there's sort of the scope and scale of war, but to imagine that there would not be any war in the future, I think would be a very unlikely outcome.", "chunk": 1}], "start": 581.94, "end": 595.68}, {"speaker": 0, "transcript": [{"text": "Yeah, you talked about the culture series, there's war even there.", "chunk": 1}], "start": 595.84, "end": 598.72}, {"speaker": 1, "transcript": [{"text": "Yes, it was a giant war.", "chunk": 1}, {"text": "The first book starts off with a gigantic galactic war where trillions die, trillions.", "chunk": 1}], "start": 600.04, "end": 606.6}, {"speaker": 0, "transcript": [{"text": "But it still nevertheless protects these pockets of flourishing.", "chunk": 1}, {"text": "Somehow you can have galactic war and still have pockets of flourishing.", "chunk": 1}], "start": 612.62, "end": 617.0}, {"speaker": 1, "transcript": [{"text": "Yeah, I mean, I guess if we are able to 1 day expand to, you know, full the galaxy or whatever, there won't be a galactic war at some point.", "chunk": 1}], "start": 617.96, "end": 630.34}, {"speaker": 0, "transcript": [{"text": "Ah, the scale.", "chunk": 1}, {"text": "I mean, the scale of war has been increasing, increasing, increasing.", "chunk": 1}, {"text": "It's like a race between the scale of suffering and the scale of flourishing.", "chunk": 1}], "start": 635.02, "end": 638.46}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 1}], "start": 638.68, "end": 639.18}, {"speaker": 0, "transcript": [{"text": "A lot of people seem to be using this tragedy to beat the drums of war and feed the military industrial complex.", "chunk": 1}, {"text": "Do you worry about this?", "chunk": 2}, {"text": "The people who are rooting for escalation and how can it be stopped?", "chunk": 2}], "start": 649.7, "end": 655.38}, {"speaker": 1, "transcript": [{"text": "1 of the things that does concern me is that there are very few people alive today who actually viscerally understand the horrors of war, at least in the US.", "chunk": 2}, {"text": "I mean, obviously, the people on the front lines in Ukraine and Russia who understand just how terrible war is, but how many people in the West understand it.", "chunk": 2}, {"text": "My grandfather was in World War II.", "chunk": 2}, {"text": "He was severely traumatized.", "chunk": 2}, {"text": "He was there for almost 6 years in Eastern North Africa and Italy.", "chunk": 2}], "start": 679.5, "end": 685.56}, {"speaker": 1, "transcript": [{"text": "All his friends were killed in front of him.", "chunk": 2}, {"text": "And He would have died too, except they randomly gave some, I guess IQ test or something, and he scored very high.", "chunk": 2}, {"text": "He was not an officer, he was a corporal or sergeant or something like that, because he didn't finish high school, because he had to drop out of high school because his, his, his dad died and he had to work to support his, siblings.", "chunk": 2}, {"text": "So because he didn't graduate high school, he was not eligible for the officer core.", "chunk": 2}, {"text": "So.", "chunk": 2}], "start": 717.92, "end": 718.42}, {"speaker": 1, "transcript": [{"text": "You know, he kind of got put into the cannon fodder category basically.", "chunk": 2}, {"text": "But then just randomly they gave him this test.", "chunk": 2}, {"text": "He was transferred to British intelligence in London.", "chunk": 2}, {"text": "That's where he met my grandmother.", "chunk": 2}, {"text": "But he had PTSD next level, like next level.", "chunk": 2}], "start": 733.44, "end": 737.44}, {"speaker": 1, "transcript": [{"text": "I mean, just didn't talk, just didn't talk.", "chunk": 2}, {"text": "And if you tried talking to him, he'd just tell you to shut up.", "chunk": 2}, {"text": "And he won a bunch of medals, never ragged about it once.", "chunk": 2}, {"text": "Not even hinted, nothing.", "chunk": 2}, {"text": "I like found out about it because his military records were online.", "chunk": 2}], "start": 750.26, "end": 753.62}, {"speaker": 1, "transcript": [{"text": "That's how I know.", "chunk": 2}, {"text": "So he would say, no way in hell do you want to do that again.", "chunk": 2}, {"text": "But how many people?", "chunk": 2}, {"text": "Now, he died 20 years ago, or longer, actually, 30 years ago.", "chunk": 2}, {"text": "How many people are alive that remember World War II?", "chunk": 2}], "start": 770.66, "end": 772.86}, {"speaker": 1, "transcript": [{"text": "Not many.", "chunk": 2}], "start": 773.16, "end": 773.84}, {"speaker": 0, "transcript": [{"text": "And the same perhaps applies to the threat of nuclear war.", "chunk": 2}], "start": 774.72, "end": 778.26}, {"speaker": 1, "transcript": [{"text": "Yeah, I mean, there are enough nuclear bombs pointed at the United States to make the rubble, the radioactive rubble bounce many times.", "chunk": 2}], "start": 781.06, "end": 788.8}, {"speaker": 0, "transcript": [{"text": "There's 2 major wars going on right now.", "chunk": 2}, {"text": "So you talked about the threat of AGI quite a bit, but now as we sit here with the intensity of conflict going on, do you worry about nuclear war?", "chunk": 2}], "start": 794.44, "end": 803.84}, {"speaker": 1, "transcript": [{"text": "I think we shouldn't discount the possibility of nuclear war.", "chunk": 2}, {"text": "It is a civilizational threat.", "chunk": 2}, {"text": "Right now, I could be wrong, but I think that the current probability of nuclear war is quite low.", "chunk": 2}, {"text": "But there are a lot of nukes pointed at us.", "chunk": 2}, {"text": "And we have a lot of nukes pointed at other people.", "chunk": 2}], "start": 827.06, "end": 829.22}, {"speaker": 1, "transcript": [{"text": "They're still there.", "chunk": 2}, {"text": "Nobody's put their guns away.", "chunk": 2}, {"text": "The missiles are still in the silos.", "chunk": 2}], "start": 835.24, "end": 836.78}, {"speaker": 0, "transcript": [{"text": "And the leaders don't seem to be the ones with the nukes talking to each other.", "chunk": 2}], "start": 837.5, "end": 842.94}, {"speaker": 1, "transcript": [{"text": "No.", "chunk": 2}, {"text": "There are wars which are tragic and difficult on a local basis.", "chunk": 2}, {"text": "And then there are wars which are civilization ending or have that potential.", "chunk": 2}, {"text": "Obviously global thermonuclear warfare has high potential to end civilization, perhaps permanently, but certainly, you know, to severely wound and perhaps set back human progress by, you know, the Stone Age or something.", "chunk": 2}, {"text": "I don't know.", "chunk": 2}], "start": 873.58, "end": 874.34}, {"speaker": 1, "transcript": [{"text": "Pretty bad.", "chunk": 2}, {"text": "Probably scientists and engineers won't be super popular after that as well.", "chunk": 2}, {"text": "They're like, you got us into this mess.", "chunk": 2}, {"text": "So, generally, I think we obviously want to prioritize civilizational risks over things that are painful and tragic on a local level, but not civilizational.", "chunk": 2}], "start": 886.06, "end": 896.72}, {"speaker": 0, "transcript": [{"text": "How do you hope the war in Ukraine comes to an end?", "chunk": 2}, {"text": "And what's the path once again to minimizing human suffering there?", "chunk": 2}], "start": 902.56, "end": 906.1}, {"speaker": 1, "transcript": [{"text": "Well, I think that what is likely to happen, which is really pretty much the way it is, is that something very close to the current lines will be how a ceasefire or truce happens.", "chunk": 2}, {"text": "But you just have a situation right now where whoever goes on the offensive will suffer casualties at several times the rate of whoever's on the defense.", "chunk": 2}, {"text": "Because you've got defense in depth, you've got minefields, trenches, anti-tank defenses.", "chunk": 2}, {"text": "Nobody has air superiority, because the anti-aircraft missiles are really far better than the aircraft.", "chunk": 2}, {"text": "Like they're far more of them.", "chunk": 2}], "start": 955.6, "end": 956.88}, {"speaker": 1, "transcript": [{"text": "And so neither side has air superiority.", "chunk": 2}, {"text": "Tanks are basically death traps, just slow moving, and they're not immune to anti-tank weapons.", "chunk": 2}, {"text": "So you really just have long range artillery and infantry trenches.", "chunk": 2}, {"text": "It's all to 1, all over again.", "chunk": 2}, {"text": "With drones, you know, throwing old drones, some drones there.", "chunk": 2}], "start": 981.14, "end": 984.3}, {"speaker": 0, "transcript": [{"text": "Which makes the long range artillery just that much more accurate and better and so more efficient murdering people on both sides", "chunk": 2}], "start": 985.36, "end": 992.36}, {"speaker": 1, "transcript": [{"text": "yeah so it's whoever is you don't you don't you don't want to be trying to advance from either side because the probability of dying is incredibly high.", "chunk": 2}, {"text": "So in order to overcome defense in depth trenches and minefields, you really need significant local superiority in numbers.", "chunk": 2}, {"text": "Ideally combined arms where you do a fast attack with aircraft, a concentrated number of tanks, and a lot of people.", "chunk": 2}, {"text": "That's the only way you're going to punch through a line.", "chunk": 2}, {"text": "And then you're going to punch through and, and then not have the reinforcements just kick you right out again.", "chunk": 2}], "start": 1032.24, "end": 1039.34}, {"speaker": 1, "transcript": [{"text": "I mean, I really recommend people read World War I warfare in detail.", "chunk": 2}, {"text": "That's rough.", "chunk": 2}, {"text": "I mean, the sheer number of people that died there was mind-boggling.", "chunk": 2}], "start": 1052.96, "end": 1055.82}, {"speaker": 0, "transcript": [{"text": "And it's almost impossible to imagine the end of it that doesn't look like, almost exactly like the beginning in terms of what land belongs to who and so on.", "chunk": 2}, {"text": "But on the other side of a lot of human suffering, death and destruction of infrastructure.", "chunk": 3}], "start": 1069.06, "end": 1075.7}, {"speaker": 1, "transcript": [{"text": "Yes, the thing that, the reason I proposed a some sort of crucial or peace a year ago was because I predicted pretty much exactly what would happen, which is a lot of people dying for basically almost no changes in land.", "chunk": 3}, {"text": "And the loss of the flower of Ukrainian and Russian youth, and we should have some sympathy for the Russian boys as well as the Ukrainian boys, because the Russian boys didn't ask to be on their frontline.", "chunk": 3}, {"text": "They have to be.", "chunk": 3}, {"text": "So, there's a lot of sons not coming back to their parents, you know, and I think most of them don't really have, they don't hit the other side.", "chunk": 3}, {"text": "You know, It's sort of like, as the saying comes from World War I, it's like young boys who don't know each other killing each other on behalf of old men that do know each other.", "chunk": 3}], "start": 1124.64, "end": 1137.42}, {"speaker": 1, "transcript": [{"text": "What the hell's the point of that?", "chunk": 3}], "start": 1139.58, "end": 1140.9}, {"speaker": 0, "transcript": [{"text": "So Volodymyr Zelensky said that he's not or has said in the past he's not interested in talking to Putin directly.", "chunk": 3}, {"text": "Do you think he should sit down, man-to-man, lead a leader and negotiate peace?", "chunk": 3}], "start": 1148.4, "end": 1153.06}, {"speaker": 1, "transcript": [{"text": "I think I would just recommend do not send the flower of Ukrainian youth to die in trenches.", "chunk": 3}, {"text": "Whether you talk to Putin or not, just don't do that.", "chunk": 3}, {"text": "Whoever goes on the offensive will lose massive numbers of people.", "chunk": 3}, {"text": "And history will not look kindly upon them.", "chunk": 3}], "start": 1177.42, "end": 1179.52}, {"speaker": 0, "transcript": [{"text": "You've spoken honestly about the possibility of war between US and China in the long term if no diplomatic solution is found.", "chunk": 3}, {"text": "For example, on the question of Taiwan and 1 China policy, how do we avoid the trajectory where these 2 superpowers clash?", "chunk": 3}], "start": 1189.0, "end": 1196.62}, {"speaker": 1, "transcript": [{"text": "Well, it's worth reading that book on the, difficult to pronounce, the Ossetia's trap, I believe it's called.", "chunk": 3}, {"text": "I love war history, I like inside out and backwards.", "chunk": 3}, {"text": "There's hardly a battle I haven't read about.", "chunk": 3}, {"text": "And trying to figure out like what really was the cause of victory in any particular case, as opposed to what 1 side or another claimed was the reason.", "chunk": 3}], "start": 1213.62, "end": 1220.78}, {"speaker": 0, "transcript": [{"text": "Both the victory and what sparked the war and the whole thing.", "chunk": 3}], "start": 1221.42, "end": 1226.16}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 3}, {"text": "So Athens and Sparta is a classic case.", "chunk": 3}, {"text": "The thing about the Greeks is they really wrote down a lot of stuff.", "chunk": 3}, {"text": "They loved writing.", "chunk": 3}, {"text": "There are lots of interesting things that happened in many parts of the world, but people just didn't write down.", "chunk": 3}], "start": 1233.82, "end": 1237.74}, {"speaker": 1, "transcript": [{"text": "So we don't know what happened.", "chunk": 3}, {"text": "Or they didn't really write in detail.", "chunk": 3}, {"text": "They just would say, like, we had a battle and we won and like what can you add a bit more the Greeks they really wrote a lot they're very articulate on it they just love writing so and we have a bunch of that writing that's preserved so we know what led up to the Peloponnesian War between the Spartan and Athenian alliance.", "chunk": 3}, {"text": "And we know that they saw it coming.", "chunk": 3}, {"text": "I mean, the Spartans didn't write, they also weren't very verbose by their nature.", "chunk": 3}], "start": 1275.68, "end": 1279.48}, {"speaker": 1, "transcript": [{"text": "But they did write, but they weren't verbose.", "chunk": 3}, {"text": "They were terse.", "chunk": 3}, {"text": "But the Athenians and the other Greeks wrote a line.", "chunk": 3}, {"text": "And they were like, and Sparta was really kind of like the leader of Greece.", "chunk": 3}, {"text": "But Athens grew stronger and stronger with each passing year.", "chunk": 3}], "start": 1293.9, "end": 1296.94}, {"speaker": 1, "transcript": [{"text": "And everyone's like, well, that's inevitable that there's going to be a clash between Athens and Sparta.", "chunk": 3}, {"text": "Well, how do we avoid that?", "chunk": 3}, {"text": "And they couldn't, they couldn't, they actually, they saw it coming and they still could not avoid it.", "chunk": 3}, {"text": "So, you know, at some point if there's, if 1 group, 1 civilization or country or whatever exceeds another, sort of like, you know, the United States has been the biggest kid on the block since I think around 1890 from an economic standpoint.", "chunk": 3}, {"text": "So the United States has been the economic, most powerful economic engine in the world longer than anyone's been alive.", "chunk": 3}], "start": 1334.52, "end": 1343.9}, {"speaker": 1, "transcript": [{"text": "And the foundation of war is economics.", "chunk": 3}, {"text": "So, now we have a situation in case of China where the economy is likely to be 2, perhaps 3 times larger than that of the US.", "chunk": 3}, {"text": "So, imagine you're the biggest kid on the block for as long as anyone can remember, and suddenly a kid comes along who's twice your size.", "chunk": 3}], "start": 1365.82, "end": 1371.94}, {"speaker": 0, "transcript": [{"text": "So we see it coming.", "chunk": 3}, {"text": "Yeah.", "chunk": 3}, {"text": "How is it possible to stop?", "chunk": 3}, {"text": "Is there some, let me throw something out there, just intermixing of cultures, understanding.", "chunk": 3}, {"text": "There does seem to be a giant cultural gap and understanding of each other.", "chunk": 3}], "start": 1386.18, "end": 1389.6}, {"speaker": 0, "transcript": [{"text": "And you're an interesting case study because you are an American, obviously.", "chunk": 3}, {"text": "You've done a lot of incredible manufacture here in the United States, but you also work with China.", "chunk": 3}], "start": 1394.1, "end": 1399.8401}, {"speaker": 1, "transcript": [{"text": "I've spent a lot of time in China and met with the leadership many times.", "chunk": 3}], "start": 1399.8401, "end": 1402.96}, {"speaker": 0, "transcript": [{"text": "Maybe a good question to ask is, what are some things about China that people don't understand, positive, just in the culture?", "chunk": 3}, {"text": "What's some interesting things that you've learned about the Chinese?", "chunk": 3}], "start": 1409.92, "end": 1412.98}, {"speaker": 1, "transcript": [{"text": "Well, the sheer number of really smart, hardworking people in China is incredible.", "chunk": 3}, {"text": "There are really, so like, how many smart hardworking people are there in China, there's far more of them there than they are here, I think in my opinion.", "chunk": 3}, {"text": "They've got a lot of energy.", "chunk": 3}, {"text": "So, I mean the architecture in China that's in recent years is far more impressive than the US.", "chunk": 3}, {"text": "I mean, the train stations, the buildings, the high-speed rail, everything, it's really far more impressive than what we have in the US.", "chunk": 3}], "start": 1448.4, "end": 1459.24}, {"speaker": 1, "transcript": [{"text": "I mean, I recommend somebody just go to Shanghai and Beijing, look at the buildings and go to take the train from Beijing to Xi'an where you have the terracotta warriors.", "chunk": 3}, {"text": "China's got an incredible history, very long history.", "chunk": 4}, {"text": "I think arguably in terms of the use of language from a written standpoint, sort of 1 of the oldest, perhaps the oldest written language.", "chunk": 4}, {"text": "And in China, people did write things down.", "chunk": 4}, {"text": "So now China historically has always been, with rare exception, been internally focused.", "chunk": 4}], "start": 1490.78, "end": 1498.9}, {"speaker": 1, "transcript": [{"text": "They've not been acquisitive.", "chunk": 4}, {"text": "They've fought each other.", "chunk": 4}, {"text": "There have been many, many civil wars.", "chunk": 4}, {"text": "In the 3 Kingdoms War, I believe they lost about 70% of their population.", "chunk": 4}, {"text": "So they've had brutal internal wars, like civil wars that make the US Civil War look small by comparison.", "chunk": 4}], "start": 1515.52, "end": 1525.14}, {"speaker": 1, "transcript": [{"text": "So I think it's important to appreciate that China is not monolithic.", "chunk": 4}, {"text": "We sort of think of China as this 1 entity of 1 mind, and this is definitely not the case.", "chunk": 4}, {"text": "From what I've seen, And I think most people who understand China would agree that people in China think about China 10 times more than they think about anything outside of China.", "chunk": 4}, {"text": "So it's like 90% of their consideration is, you know, is internal.", "chunk": 4}], "start": 1553.86, "end": 1560.76}, {"speaker": 0, "transcript": [{"text": "Well, isn't that a really positive thing?", "chunk": 4}, {"text": "When you're talking about the collaboration and the future piece between superpowers, when you're inward facing, which is like focusing on improving yourself versus focusing on quote unquote improving others through military might.", "chunk": 4}], "start": 1563.78, "end": 1577.66}, {"speaker": 1, "transcript": [{"text": "The good news, the history of China suggests that China is not acquisitive, meaning they're not gonna go out and invade a whole bunch of countries.", "chunk": 4}, {"text": "Now they do feel very strongly, you know, so that's good.", "chunk": 4}, {"text": "I mean, cause a lot of very powerful countries have been acquisitive.", "chunk": 4}, {"text": "The US is also 1 of the rare cases that has not been acquisitive.", "chunk": 4}, {"text": "After World War II, the US could have basically taken over the world and any country.", "chunk": 4}], "start": 1599.16, "end": 1602.82}, {"speaker": 1, "transcript": [{"text": "Like we got nukes, nobody else got nukes.", "chunk": 4}, {"text": "We don't even have to lose soldiers.", "chunk": 4}, {"text": "Which country do you want?", "chunk": 4}, {"text": "And the United States could have taken over everything.", "chunk": 4}, {"text": "Or it had will, and it didn't.", "chunk": 4}], "start": 1612.38, "end": 1614.08}, {"speaker": 1, "transcript": [{"text": "And the United States actually helped rebuild countries.", "chunk": 4}, {"text": "So it helped rebuild Europe.", "chunk": 4}, {"text": "It helped rebuild Japan.", "chunk": 4}, {"text": "This is very unusual behavior, almost unprecedented.", "chunk": 4}, {"text": "The US did conspicuous acts of kindness, like the Berlin airlift.", "chunk": 4}], "start": 1630.04, "end": 1634.4}, {"speaker": 1, "transcript": [{"text": "It's always like, well, America's done bad things.", "chunk": 4}, {"text": "Well, of course America's done bad things, but 1 needs to look at the whole track record.", "chunk": 4}, {"text": "And just generally, you know, 1 sort of test would be, how do you treat your prisoners of war?", "chunk": 4}, {"text": "Or let's say, you know, no offense to the Russians, but let's say you're in Germany, it's 1945, you've got the Russian army coming 1 side, you got the French, British and American armies coming the other side.", "chunk": 4}, {"text": "Who would you like to be to surrender to?", "chunk": 4}], "start": 1673.04, "end": 1675.98}, {"speaker": 1, "transcript": [{"text": "Like no country is like morally perfect, but I recommend being a POW with the Americans.", "chunk": 4}, {"text": "That would be my choice very strongly.", "chunk": 4}, {"text": "In", "chunk": 4}], "start": 1686.3501, "end": 1686.8501}, {"speaker": 0, "transcript": [{"text": "the full menu of POW.", "chunk": 4}], "start": 1687.56, "end": 1688.96}, {"speaker": 1, "transcript": [{"text": "Very much so.", "chunk": 4}, {"text": "And in fact, von Braun, a small guy, was like, we've got to be captured by the Americans.", "chunk": 4}, {"text": "Yeah.", "chunk": 4}, {"text": "And in fact, the SS was under orders to execute von Braun and all of the German recognitionists.", "chunk": 4}, {"text": "And they narrowly escaped their SSR.", "chunk": 4}], "start": 1710.74, "end": 1714.26}, {"speaker": 1, "transcript": [{"text": "They said they were going out for a walk in the woods.", "chunk": 4}, {"text": "They left in the middle of winter with no coats.", "chunk": 4}, {"text": "And they ran like, no food, no coats, no water.", "chunk": 4}, {"text": "And just ran like hell and ran west.", "chunk": 4}, {"text": "And by sheer luck, I think his brother found a bicycle or something and then just cycled as fast as he could and found a US patrol.", "chunk": 4}], "start": 1726.08, "end": 1736.6}, {"speaker": 1, "transcript": [{"text": "So Anyway, that's 1 way you can tell morality is, where do you want to be a PW?", "chunk": 4}, {"text": "It's not fun anywhere, but some places are much worse than others.", "chunk": 4}, {"text": "So, like America has been, well, far from perfect, generally a benevolent force.", "chunk": 4}, {"text": "And we should always be self-critical and try to be better.", "chunk": 4}, {"text": "But anyone with half a brain knows that.", "chunk": 4}], "start": 1767.66, "end": 1770.06}, {"speaker": 1, "transcript": [{"text": "So I think there are, in this way, China and the United States are similar.", "chunk": 4}, {"text": "Neither country has been acquisitive in a significant way.", "chunk": 4}, {"text": "So that's like a shared principle, I guess.", "chunk": 4}, {"text": "Now China does feel very strongly about Taiwan.", "chunk": 4}, {"text": "They've been very clear about that for a long time.", "chunk": 4}], "start": 1791.66, "end": 1794.66}, {"speaker": 1, "transcript": [{"text": "From their standpoint, it would be like 1 of the states is not there, like Hawaii or something like that, but more significant than Hawaii.", "chunk": 4}, {"text": "And Hawaii is pretty significant for us.", "chunk": 4}, {"text": "So they view it as really the, there's a fundamental part of China, the island of Formosa, not Taiwan, that is not part of China, but should be.", "chunk": 4}, {"text": "And the only reason it hasn't been is because the US Pacific fleet.", "chunk": 4}], "start": 1827.66, "end": 1830.98}, {"speaker": 0, "transcript": [{"text": "And as their economic power grows, and is their military power grows?", "chunk": 4}, {"text": "The thing that they are clearly saying is their interests will, you know, clearly be materialized.", "chunk": 4}], "start": 1836.44, "end": 1845.44}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 4}, {"text": "China has been very clear that they will incorporate Taiwan peacefully or militarily, but that they will incorporate it from their standpoint is 100% likely.", "chunk": 4}], "start": 1848.12, "end": 1862.96}, {"speaker": 0, "transcript": [{"text": "You know, something you said about conspicuous acts of kindness as a geopolitical policy, it almost seems naive, but I'd venture to say that this is probably the path forward, how you avoid most wars.", "chunk": 4}, {"text": "Just as you say it, it sounds naive, but it's kind of brilliant if you believe in the goodness of underlying most of human nature.", "chunk": 4}, {"text": "It just seems like conspicuous acts of kindness can reverberate through the populace of the countries involved and de-escalate.", "chunk": 4}, {"text": "Absolutely.", "chunk": 4}], "start": 1902.6, "end": 1903.1}, {"speaker": 1, "transcript": [{"text": "After World War I, they made a big mistake.", "chunk": 4}, {"text": "They basically tried to lump all the blame on Germany and settled Germany with impossible reparations.", "chunk": 4}, {"text": "And really, there was quite a bit of blame to go around for World War I, but they tried to put it all on Germany.", "chunk": 4}, {"text": "And that laid the seeds for World War 2.", "chunk": 4}, {"text": "So that's a lot of people were not just Hitler, a lot of people felt wronged.", "chunk": 4}], "start": 1945.26, "end": 1950.12}, {"speaker": 1, "transcript": [{"text": "And they wanted vengeance.", "chunk": 4}, {"text": "And they got it.", "chunk": 4}, {"text": "People don't forget.", "chunk": 4}, {"text": "Yeah.", "chunk": 4}, {"text": "You kill somebody's father, mother, son, daughter, they're not gonna forget it.", "chunk": 4}], "start": 1962.04, "end": 1967.26}, {"speaker": 1, "transcript": [{"text": "They will want vengeance.", "chunk": 4}, {"text": "So after World War II, they're like, well, that Treaty of Versailles was a huge mistake in World War I.", "chunk": 4}, {"text": "And so this time, instead of, you know, crushing the losers, we're actually going to help them with the Marshall Plan and we're going to help rebuild Germany.", "chunk": 4}, {"text": "We're going to help rebuild Austria and the other, Italy and whatnot.", "chunk": 4}, {"text": "That was the right move.", "chunk": 4}], "start": 2001.0734, "end": 2005.9467}, {"speaker": 0, "transcript": [{"text": "There is a, it does feel like there's a profound truth to, conspicuous acts of kindness being an antidote to this.", "chunk": 4}], "start": 2006.54, "end": 2015.34}, {"speaker": 1, "transcript": [{"text": "Something must stop the cycle of reciprocal violence.", "chunk": 5}, {"text": "Something must stop it or it will, you know, It'll never stop.", "chunk": 5}, {"text": "Just eye for an eye, tooth for a tooth, limb for a limb, life for a life, forever and ever.", "chunk": 5}], "start": 2027.16, "end": 2035.04}, {"speaker": 0, "transcript": [{"text": "To escape briefly the darkness with some incredible engineering work.", "chunk": 5}, {"text": "XAI just released Grok, AI assistant that I've gotten a chance to play with.", "chunk": 5}, {"text": "It's amazing on many levels.", "chunk": 5}, {"text": "First of all, it's amazing that a relatively small team in a relatively short amount of time was able to develop this closest state-of-the-art system.", "chunk": 5}, {"text": "Another incredible thing is there's a regular mode and there's a fun mode.", "chunk": 5}], "start": 2059.16, "end": 2063.1}, {"speaker": 1, "transcript": [{"text": "Yeah, I guess I'm to blame for that 1.", "chunk": 5}], "start": 2063.1, "end": 2065.02}, {"speaker": 0, "transcript": [{"text": "I wish, first of all, I wish everything in life had a fun mode.", "chunk": 5}, {"text": "Yeah.", "chunk": 5}, {"text": "There's something compelling beyond just fun about the fun mode interacting with a large language model.", "chunk": 5}, {"text": "I'm not sure exactly what it is because I've only had a little bit of time to play with it, but it just makes it more interesting, more vibrant to interact with the system.", "chunk": 5}], "start": 2078.22, "end": 2087.86}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 5}, {"text": "Absolutely.", "chunk": 5}, {"text": "I, our AI grok is modeled after the Hitchhiker's Guide to the Galaxy, which is 1 of my favorite books, which is a book on philosophy, disguises a book on humor.", "chunk": 5}, {"text": "And I would say that is that forms the basis of my philosophy, which is that we don't know the meaning of life.", "chunk": 5}, {"text": "But the more we can expand the scope and scale of consciousness, digital and biological, the more we're able to understand what questions to ask about the answer that is the universe.", "chunk": 5}], "start": 2116.5, "end": 2128.92}, {"speaker": 1, "transcript": [{"text": "So I have a philosophy of curiosity.", "chunk": 5}], "start": 2130.06, "end": 2132.32}, {"speaker": 0, "transcript": [{"text": "There is generally a feeling like this AI system has an outward looking, like the way you are sitting with a good friend, looking up at the stars, like asking pothead questions about the universe, wondering what it's all about, the curiosity you talk about.", "chunk": 5}, {"text": "There's a sense, no matter how mundane the question, I ask it, there's a sense of cosmic grandeur to the whole", "chunk": 5}], "start": 2152.46, "end": 2158.78}, {"speaker": 1, "transcript": [{"text": "thing.", "chunk": 5}, {"text": "Well, we are actually working hard to have engineering, math, physics answers that you can count on.", "chunk": 5}, {"text": "So for the other sort of AIs out there, the so-called large language models, I've not found the engineering to be reliable and the hallucination, it unfortunately hallucinates most when you least want it to hallucinate.", "chunk": 5}, {"text": "So when you ask important difficult questions, that's when it tends to be confidently wrong.", "chunk": 5}, {"text": "So we're really trying hard to say, okay, how do we be as grounded as possible so you can count on the results?", "chunk": 5}], "start": 2196.3, "end": 2203.36}, {"speaker": 1, "transcript": [{"text": "Trace things back to physics first principles, mathematical logic.", "chunk": 5}, {"text": "So underlying the humor is an aspiration to adhere to the truth of the universe as closely as possible.", "chunk": 5}], "start": 2211.52, "end": 2219.98}, {"speaker": 0, "transcript": [{"text": "That's really tricky.", "chunk": 5}], "start": 2221.36, "end": 2222.46}, {"speaker": 1, "transcript": [{"text": "It is tricky.", "chunk": 5}, {"text": "So, that's why, you know, there's always going to be some amount of error, but we want to aspire to be as truthful as possible about the answers with acknowledged error.", "chunk": 5}, {"text": "So that there was always, you don't want to be confidently wrong.", "chunk": 5}, {"text": "So you're not going to be right every time, but you don't want to minimize how often you're confidently wrong.", "chunk": 5}, {"text": "And then like I said, once you can count on the logic as being not violating physics, then you can start to build on that to create inventions, like invent new technologies.", "chunk": 5}], "start": 2251.28, "end": 2265.08}, {"speaker": 1, "transcript": [{"text": "But if you cannot count on the foundational physics being correct, obviously the inventions are simply wishful thinking, you know, imagination land, magic basically.", "chunk": 5}], "start": 2267.52, "end": 2280.24}, {"speaker": 0, "transcript": [{"text": "Well, as you said, I think 1 of the big goals of XAI is to understand the universe.", "chunk": 5}], "start": 2281.3, "end": 2285.84}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 5}, {"text": "That's how simple three-word mission.", "chunk": 5}], "start": 2287.8, "end": 2290.56}, {"speaker": 0, "transcript": [{"text": "If you look out far into the future, do you think on this level of physics, the very edge of what we understand about physics, do you think it will make discoveries sort of the sexiest discovery of them as we know now, sort of unifying general relativity and quantum mechanics?", "chunk": 5}, {"text": "So coming up with a theory of everything.", "chunk": 5}, {"text": "Do you think it could push towards that direction, almost like theoretical physics discoveries?", "chunk": 5}], "start": 2312.78, "end": 2317.48}, {"speaker": 1, "transcript": [{"text": "If an AI cannot figure out new physics, it's clearly not equal to humans, let alone nor has surpass humans because humans have figured out new physics.", "chunk": 5}, {"text": "They're just good.", "chunk": 5}, {"text": "Physics is just understanding, deepening one's insight into how reality works.", "chunk": 5}, {"text": "And then, then there's engineering, which is inventing things that have never existed.", "chunk": 5}, {"text": "Now the range of possibilities for engineering is far greater than for physics because, you know, once you figure out the rules of the universe, that's it.", "chunk": 5}], "start": 2341.04, "end": 2349.82}, {"speaker": 1, "transcript": [{"text": "You've discovered things that already existed.", "chunk": 5}, {"text": "But from that, you can then build technologies that are really almost limitless in the variety and, you know, it's like once you understand the rules of the game properly.", "chunk": 5}, {"text": "And we do, you know, with current physics, we do, at least at a local level, understand how physics works very well.", "chunk": 5}, {"text": "We are really good at predicting things, it's incredibly good.", "chunk": 5}, {"text": "The degree to which quantum mechanics can predict outcomes is incredible.", "chunk": 5}], "start": 2375.24, "end": 2380.5}, {"speaker": 1, "transcript": [{"text": "That was my hardest class in college, by the way.", "chunk": 5}, {"text": "My senior quantum mechanics class was harder than all of my other classes put together.", "chunk": 5}], "start": 2386.12, "end": 2389.86}, {"speaker": 0, "transcript": [{"text": "To get an AI system, a large language model to reliably be as reliable as quantum mechanics and physics is very difficult.", "chunk": 5}], "start": 2390.01, "end": 2400.56}, {"speaker": 1, "transcript": [{"text": "Yeah, you have to test any conclusions against the ground truth of reality.", "chunk": 5}, {"text": "Reality is the ultimate judge.", "chunk": 5}, {"text": "Like physics is the law, everything else is a recommendation.", "chunk": 5}, {"text": "I've seen plenty of people break the break the laws made by man, but none break the laws made by physics.", "chunk": 5}], "start": 2409.78, "end": 2415.34}, {"speaker": 0, "transcript": [{"text": "It's a good test.", "chunk": 5}, {"text": "Actually, if this LM understands and matches physics, then you can more reliably trust whatever it thinks about the current state of politics.", "chunk": 5}], "start": 2416.46, "end": 2426.36}, {"speaker": 1, "transcript": [{"text": "And it's also not the case currently that even that its internal logic is not consistent.", "chunk": 5}, {"text": "So especially with the approach of like just predicting a token predict, token predict, token, it's like a vector sum.", "chunk": 5}, {"text": "You know, you're summing up a bunch of vectors, but you can get drift.", "chunk": 5}, {"text": "So as those, a little bit of error, a little bit of error adds up.", "chunk": 5}, {"text": "And by the time you are many tokens down the path, it doesn't make any sense.", "chunk": 5}], "start": 2453.06, "end": 2458.78}, {"speaker": 0, "transcript": [{"text": "So It has to be somehow self-aware about the drift.", "chunk": 5}], "start": 2459.66, "end": 2462.36}, {"speaker": 1, "transcript": [{"text": "It has to be self-aware about the drift and then look at the thing as a gestalt as a whole and say, it doesn't have coherence as a whole.", "chunk": 5}, {"text": "So, You know, when authors write books, that they will write the book and then they'll go and revise it, taking into account all the end and the beginning and the middle and rewrite it to achieve coherence so that it doesn't end up in a nonsensical place.", "chunk": 5}], "start": 2473.62, "end": 2493.28}, {"speaker": 0, "transcript": [{"text": "Maybe the process of revising is what reasoning is.", "chunk": 6}, {"text": "And then the process of revising is how you get closer and closer to truth.", "chunk": 6}, {"text": "Maybe you like, at least I approach it that way.", "chunk": 6}, {"text": "You just say a bunch of bullshit first and then you get it better.", "chunk": 6}, {"text": "You start a bullshit and", "chunk": 6}], "start": 2507.69, "end": 2508.5479}, {"speaker": 1, "transcript": [{"text": "then you", "chunk": 6}], "start": 2508.5479, "end": 2508.676}, {"speaker": 0, "transcript": [{"text": "get it.", "chunk": 6}, {"text": "Yeah, you create", "chunk": 6}], "start": 2509.08, "end": 2509.74}, {"speaker": 1, "transcript": [{"text": "a draft and then you iterate on that draft until it has coherence, until it all adds up basically.", "chunk": 6}], "start": 2509.74, "end": 2518.12}, {"speaker": 0, "transcript": [{"text": "So another question about theory of everything but for intelligence.", "chunk": 6}, {"text": "Do you think there exists, as you're exploring this with XAI, creating this intelligence system, do you think there is a theory of intelligence where you get to understand what, like, what is the I in AGI and what is the eye in human intelligence?", "chunk": 6}], "start": 2522.62, "end": 2541.94}, {"speaker": 1, "transcript": [{"text": "There's no eye in Team America.", "chunk": 6}, {"text": "Oh, wait, there is.", "chunk": 6}], "start": 2543.74, "end": 2544.68}, {"speaker": 0, "transcript": [{"text": "Oh, now it's going to be stuck in my head now.", "chunk": 6}, {"text": "Yeah.", "chunk": 6}, {"text": "There's no me in whatever in quantum mechanics.", "chunk": 6}, {"text": "Oh, wait.", "chunk": 6}, {"text": "I mean, is that part of the process of discovering, understanding the universe is understanding intelligence?", "chunk": 6}], "start": 2561.04, "end": 2566.5}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 6}], "start": 2567.96, "end": 2568.46}, {"speaker": 1, "transcript": [{"text": "Yeah, I think we need to understand intelligence, understand consciousness.", "chunk": 6}, {"text": "I mean, there are some sort of fundamental questions of like, what is thought?", "chunk": 6}, {"text": "What is emotion?", "chunk": 6}, {"text": "Yeah.", "chunk": 6}, {"text": "Is it really just 1 atom bumping into another atom?", "chunk": 6}], "start": 2583.06, "end": 2585.88}, {"speaker": 1, "transcript": [{"text": "It feels like something more than that.", "chunk": 6}, {"text": "So I think we're probably missing some really big things.", "chunk": 6}, {"text": "Like some really big things.", "chunk": 6}], "start": 2595.84, "end": 2597.7}, {"speaker": 0, "transcript": [{"text": "Something that'll be obvious in retrospect.", "chunk": 6}, {"text": "Yes.", "chunk": 6}, {"text": "Like there's a giant, like you put the whole consciousness, emotion.", "chunk": 6}], "start": 2601.86, "end": 2605.32}, {"speaker": 1, "transcript": [{"text": "Well, some people would call it like a soul, you know, in religion, a soul.", "chunk": 6}, {"text": "Like you feel like you're you, right?", "chunk": 6}, {"text": "I mean, you don't feel like you're just a collection of atoms, but on what dimension does thought exist?", "chunk": 6}, {"text": "What dimension does emotions exist?", "chunk": 6}, {"text": "We feel them very strongly.", "chunk": 6}], "start": 2623.74, "end": 2624.94}, {"speaker": 1, "transcript": [{"text": "I suspect there's more to it than atoms bumping into atoms.", "chunk": 6}], "start": 2626.36, "end": 2629.32}, {"speaker": 0, "transcript": [{"text": "And maybe AI can pave the path to the discovery of what whatever the hell that thing is.", "chunk": 6}], "start": 2632.16, "end": 2637.58}, {"speaker": 1, "transcript": [{"text": "Yeah, what is consciousness?", "chunk": 6}, {"text": "Like what When you put the atoms in a particular shape, why are they able to form thoughts and take actions and feelings?", "chunk": 6}], "start": 2639.5, "end": 2649.0}, {"speaker": 0, "transcript": [{"text": "And even if it is an illusion, why is this illusion so compelling?", "chunk": 6}], "start": 2650.02, "end": 2653.22}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 6}, {"text": "Why does this illusion exist?", "chunk": 6}, {"text": "On what plane does this illusion exist?", "chunk": 6}, {"text": "And sometimes I wonder, is either perhaps everything's conscious or nothing is conscious.", "chunk": 6}, {"text": "1 of the 2.", "chunk": 6}], "start": 2671.16, "end": 2672.12}, {"speaker": 0, "transcript": [{"text": "I like the former.", "chunk": 6}, {"text": "Everything conscious just seems more fun.", "chunk": 6}], "start": 2674.7, "end": 2677.12}, {"speaker": 1, "transcript": [{"text": "It just seemed more, more fun.", "chunk": 6}, {"text": "Yes.", "chunk": 6}, {"text": "But we're, we're composed of atoms and those atoms are composed of quarks and leptons And those quarks and leptons have been around since the beginning of the universe.", "chunk": 6}], "start": 2681.16, "end": 2689.12}, {"speaker": 0, "transcript": [{"text": "The beginning of the universe.", "chunk": 6}], "start": 2690.12, "end": 2692.26}, {"speaker": 1, "transcript": [{"text": "Right, what seems to be the beginning of the universe.", "chunk": 6}], "start": 2693.34, "end": 2695.74}, {"speaker": 0, "transcript": [{"text": "The first time we talked, you said, which is surreal to think that this discussion was happening and is becoming a reality, I asked you what question would you ask an AGI system once you create it and you said, what's outside the simulation is the question.", "chunk": 6}, {"text": "Good question.", "chunk": 6}, {"text": "But it seems like with Grog, you started to, literally the system's goal is to be able to ask such questions, to answer such questions", "chunk": 6}], "start": 2713.68, "end": 2722.4}, {"speaker": 1, "transcript": [{"text": "and", "chunk": 6}], "start": 2722.44, "end": 2722.54}, {"speaker": 0, "transcript": [{"text": "to ask such questions.", "chunk": 6}], "start": 2722.54, "end": 2723.76}, {"speaker": 1, "transcript": [{"text": "Where are the aliens?", "chunk": 6}], "start": 2724.22, "end": 2724.98}, {"speaker": 0, "transcript": [{"text": "Where are the aliens?", "chunk": 6}], "start": 2725.26, "end": 2726.06}, {"speaker": 1, "transcript": [{"text": "That's 1 of the, like the foamy paradox question.", "chunk": 6}, {"text": "A lot of people have asked me if I've seen any evidence of aliens and I haven't, which is kind of concerning because then I think I'd probably prefer to at least have seen some archaeological evidence of aliens.", "chunk": 6}, {"text": "To the best of my knowledge, there is no proof.", "chunk": 6}, {"text": "I'm not aware of any evidence of aliens.", "chunk": 6}, {"text": "The food out there, they're very subtle.", "chunk": 6}], "start": 2749.98, "end": 2751.64}, {"speaker": 1, "transcript": [{"text": "We might just be the only consciousness at least in the galaxy.", "chunk": 6}, {"text": "And if you look at say the history of earth, for us to believe the archeological record, Earth is about 4 and a half billion years old.", "chunk": 6}, {"text": "Civilization, as measured from the first writing, is only about 5, 000 years old.", "chunk": 6}, {"text": "We have to give some credit there to the ancient Sumerians who aren't around anymore.", "chunk": 6}, {"text": "I think it was the archaic pre-cuneiform, was the first actual symbolic representation, but only about 5, 000 years ago.", "chunk": 6}], "start": 2775.48, "end": 2782.96}, {"speaker": 1, "transcript": [{"text": "I think that's a good date for when, we'll say, civilization started.", "chunk": 6}, {"text": "That's 1 millionth of Earth's existence.", "chunk": 6}, {"text": "So civilization has been around, it's really a flash in the pan so far.", "chunk": 6}, {"text": "And why have we, why did it take so long?", "chunk": 6}, {"text": "For 1 and a half billion years, for the vast majority of the time, there was no life and then there was archaic bacteria for a very long time.", "chunk": 6}], "start": 2810.72, "end": 2823.84}, {"speaker": 1, "transcript": [{"text": "And then, you know, you had mitochondria get captured, multicellular life, differentiation into plants and animals, life moving from the oceans to land, mammals, higher brain functions.", "chunk": 6}, {"text": "And the Sun is expanding slowly, but it will overheat the Earth up at some point in the future, boil the oceans and Earth will become like Venus, where life as we know it is impossible.", "chunk": 6}, {"text": "So if we do not become multi-planetary and ultimately go beyond our solar system, annihilation of all life on Earth is a certainty.", "chunk": 6}, {"text": "And it could be as little as on the galactic time scale, half a billion years.", "chunk": 6}, {"text": "You know, long time by human standards, but that's only 10% longer than Earth has been around at all.", "chunk": 6}], "start": 2889.48, "end": 2895.46}, {"speaker": 1, "transcript": [{"text": "So if life had taken 10% longer to evolve on Earth, it wouldn't exist at all.", "chunk": 6}], "start": 2896.38, "end": 2903.54}, {"speaker": 0, "transcript": [{"text": "We got a deadline coming up, but a hurry.", "chunk": 6}, {"text": "But that said, as you said, humans, intelligent life on Earth developed a lot of cool stuff very quickly.", "chunk": 6}, {"text": "It seems like becoming a multiplanetary is almost inevitable, unless we destroy this thing.", "chunk": 6}], "start": 2919.86, "end": 2925.92}, {"speaker": 1, "transcript": [{"text": "We need to do it.", "chunk": 6}, {"text": "I mean, it's not, I mean, I suspect that there, if we are able to go out there and explore other star systems that we, there's a good chance we find a whole bunch of long dead 1 planet civilizations that never made it past their home planet.", "chunk": 6}, {"text": "That's so sad.", "chunk": 6}], "start": 2943.08, "end": 2944.0}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 6}, {"text": "Also fascinating.", "chunk": 6}], "start": 2946.26, "end": 2947.04}, {"speaker": 1, "transcript": [{"text": "I mean there are various explanations for those paradoxes and 1 is just those sort of, there's these great vultures which civilizations don't pass through And 1 of those great vultures is, do you become a multi-planet civilization or not?", "chunk": 6}, {"text": "And if you don't, it's simply a matter of time before something happens on your planet, either natural or manmade that causes us to die out like the dinosaurs.", "chunk": 6}, {"text": "Where are they now?", "chunk": 6}, {"text": "That didn't have spaceships.", "chunk": 6}, {"text": "So", "chunk": 6}], "start": 2980.84, "end": 2981.34}, {"speaker": 0, "transcript": [{"text": "I think the more likely thing is cause just a, empathize with the aliens that they, they found us and they're protecting us and letting us be nice aliens, just like the tribes in the in the Amazon, they don't contact tribes or protecting them.", "chunk": 6}, {"text": "That's what", "chunk": 6}], "start": 2998.54, "end": 2999.24}, {"speaker": 1, "transcript": [{"text": "would be a nice explanation.", "chunk": 6}], "start": 2999.24, "end": 3000.26}, {"speaker": 0, "transcript": [{"text": "Or you could have like, what was it?", "chunk": 6}, {"text": "I think under Kapathi said it's like the ants and the Amazon asking, where's everybody?", "chunk": 6}], "start": 3004.06, "end": 3008.5}, {"speaker": 1, "transcript": [{"text": "Well, they do run into a lot of other rounds.", "chunk": 6}, {"text": "That's true.", "chunk": 6}, {"text": "That was,", "chunk": 6}], "start": 3013.54, "end": 3014.12}, {"speaker": 0, "transcript": [{"text": "Sounds like a good TV show.", "chunk": 6}], "start": 3016.5, "end": 3018.06}, {"speaker": 1, "transcript": [{"text": "Yeah, they literally have this big wars between various ants.", "chunk": 6}], "start": 3018.08, "end": 3020.52}, {"speaker": 0, "transcript": [{"text": "Yeah, maybe I'm just dismissing all the different diversity of ants.", "chunk": 6}], "start": 3021.66, "end": 3027.56}, {"speaker": 1, "transcript": [{"text": "You should listen to that Werner Herzog talking about the jungle.", "chunk": 6}, {"text": "It's really hilarious.", "chunk": 6}, {"text": "Have you heard it?", "chunk": 6}], "start": 3030.92, "end": 3031.86}, {"speaker": 0, "transcript": [{"text": "No, I have not.", "chunk": 6}], "start": 3031.86, "end": 3032.5}, {"speaker": 1, "transcript": [{"text": "But Werner", "chunk": 6}], "start": 3032.5, "end": 3032.9}, {"speaker": 0, "transcript": [{"text": "Herzog has a way.", "chunk": 6}], "start": 3032.9, "end": 3034.16}, {"speaker": 1, "transcript": [{"text": "You should play it for the, you know, as an interlude in the...", "chunk": 6}, {"text": "It's on YouTube.", "chunk": 6}, {"text": "It's awesome.", "chunk": 6}], "start": 3043.04, "end": 3043.72}, {"speaker": 0, "transcript": [{"text": "I love him so much.", "chunk": 6}], "start": 3045.16, "end": 3046.4}, {"speaker": 1, "transcript": [{"text": "He's great.", "chunk": 6}], "start": 3046.98, "end": 3047.66}, {"speaker": 0, "transcript": [{"text": "Was he the director of Happy People, Life and the Tiger?", "chunk": 6}, {"text": "I think also.", "chunk": 6}], "start": 3050.06, "end": 3050.7798}, {"speaker": 1, "transcript": [{"text": "He did that bear documentary.", "chunk": 6}, {"text": "The bear documentary.", "chunk": 6}, {"text": "And this thing about penguins.", "chunk": 6}], "start": 3053.1, "end": 3054.12}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 6}, {"text": "The penguin.", "chunk": 6}, {"text": "The psychoanalysis of a", "chunk": 6}], "start": 3055.92, "end": 3059.76}, {"speaker": 1, "transcript": [{"text": "penguin.", "chunk": 6}, {"text": "Yeah, the penguins headed for mountains that are 70 miles away.", "chunk": 6}, {"text": "And the penguin is just headed for doom, basically.", "chunk": 6}], "start": 3065.64, "end": 3068.04}, {"speaker": 0, "transcript": [{"text": "Well, he had a cynical take.", "chunk": 6}, {"text": "He could be just a brave explorer and there'll be great stories told about him amongst the penguin population for many centuries to come.", "chunk": 6}, {"text": "What were we talking about?", "chunk": 6}, {"text": "Okay.", "chunk": 6}], "start": 3084.8, "end": 3085.3}, {"speaker": 1, "transcript": [{"text": "Yes, aliens.", "chunk": 6}, {"text": "I mean, I don't know.", "chunk": 6}, {"text": "Look, I think the smart move is just, you know, this is the first time in the history of Earth that it's been possible for life to extend beyond Earth.", "chunk": 6}, {"text": "That window is open.", "chunk": 6}, {"text": "Now, it may be open for a long time or maybe open for a short time.", "chunk": 6}], "start": 3106.78, "end": 3110.42}, {"speaker": 1, "transcript": [{"text": "It may be open now and then never open again.", "chunk": 6}, {"text": "So I think the smart move here is to make life multi-planetary while it is possible to do so.", "chunk": 6}, {"text": "We don't want to be 1 of those lame 1 planet civilizations", "chunk": 6}], "start": 3121.12, "end": 3123.3}, {"speaker": 0, "transcript": [{"text": "that just dies out.", "chunk": 6}, {"text": "No, those are lame.", "chunk": 6}, {"text": "Yeah, lame.", "chunk": 6}], "start": 3125.48, "end": 3126.3}, {"speaker": 1, "transcript": [{"text": "They're self-respecting.", "chunk": 6}, {"text": "Civilization would be 1 planet.", "chunk": 6}], "start": 3129.6, "end": 3131.1}, {"speaker": 0, "transcript": [{"text": "There's not going to be a Wikipedia entry for 1 of those.", "chunk": 6}, {"text": "And pause.", "chunk": 6}, {"text": "Does SpaceX have an official policy for when we meet aliens?", "chunk": 6}, {"text": "No.", "chunk": 6}, {"text": "That seems irresponsible.", "chunk": 6}], "start": 3145.3, "end": 3146.34}, {"speaker": 1, "transcript": [{"text": "If I see the slightest indication that there are aliens, I will immediately post on the X platform anything I know.", "chunk": 6}], "start": 3151.92, "end": 3158.46}, {"speaker": 0, "transcript": [{"text": "It could be the most liked, reposted post of all time.", "chunk": 6}], "start": 3158.78, "end": 3162.7}, {"speaker": 1, "transcript": [{"text": "Yeah, I mean, look, we have more satellites up there right now than everyone else combined.", "chunk": 6}, {"text": "So, you know, we know if we've got to maneuver around something and we don't have to maneuver around anything.", "chunk": 6}], "start": 3168.0, "end": 3174.5}, {"speaker": 0, "transcript": [{"text": "If we go to the big questions once again, you said you're with Einstein, that you believe in the God of Spinoza.", "chunk": 7}, {"text": "Yes.", "chunk": 7}, {"text": "So, you know, that's a view of the God is like the universe and is, reveals himself through the laws of physics or as Einstein said, through the lawful harmony of the world.", "chunk": 7}], "start": 3185.38, "end": 3195.54}, {"speaker": 1, "transcript": [{"text": "Yeah, I would agree that God of the simulator or whatever, the Supreme Being or beings, reveal themselves through the physics.", "chunk": 7}, {"text": "They have creators of this existence.", "chunk": 7}, {"text": "And it's incumbent upon us to try to understand more about this wondrous creation.", "chunk": 7}], "start": 3211.0, "end": 3216.44}, {"speaker": 0, "transcript": [{"text": "Who created this thing?", "chunk": 7}, {"text": "Who's running this thing?", "chunk": 7}, {"text": "Like embodying it into a singular question with a sexy word on top of it is like focusing the mind to understand.", "chunk": 7}, {"text": "It does seem like there's a, again, it could be an illusion.", "chunk": 7}, {"text": "It seemed like there's a purpose that there's an underlying master plan of some kind.", "chunk": 7}], "start": 3232.24, "end": 3237.44}, {"speaker": 0, "transcript": [{"text": "And it", "chunk": 7}], "start": 3237.44, "end": 3238.16}, {"speaker": 1, "transcript": [{"text": "seems like.", "chunk": 7}, {"text": "It may not be a master plan in the sense.", "chunk": 7}, {"text": "So there's like, maybe an interesting answer to the question of determinism versus free will is that if we are in a simulation, the reason that these higher beings would hold a simulation is to see what happens.", "chunk": 7}, {"text": "So it's not, they don't know what happens.", "chunk": 7}, {"text": "Otherwise they wouldn't hold the simulation.", "chunk": 7}], "start": 3262.1, "end": 3263.6}, {"speaker": 1, "transcript": [{"text": "So when, when humans create a simulation, so SpaceX and Tesla, we create simulations all the time, especially for the rocket, you have to run a lot of simulations to understand what's going to happen because you can't really test the rocket until it goes to space and you want it to work.", "chunk": 7}, {"text": "So you have to simulate subsonic, supersonic, hypersonic, ascent and then coming back super high heating and orbital dynamics.", "chunk": 7}, {"text": "All this is going to be simulated.", "chunk": 7}, {"text": "So, cause you don't get very many kicks at the can.", "chunk": 7}, {"text": "But we run the simulations to see what happens.", "chunk": 7}], "start": 3304.12, "end": 3306.24}, {"speaker": 1, "transcript": [{"text": "Not if we knew what happens, we wouldn't run the simulation.", "chunk": 7}, {"text": "So if there's, so whoever created this existence, is They're running it because they don't know what's going to happen.", "chunk": 7}, {"text": "Not because they do.", "chunk": 7}], "start": 3319.34, "end": 3320.56}, {"speaker": 0, "transcript": [{"text": "So maybe we both play Diablo.", "chunk": 7}, {"text": "Maybe Diablo was created to see if a druid, your character, could defeat Uber Lilith at the end.", "chunk": 7}, {"text": "They didn't know.", "chunk": 7}], "start": 3332.56, "end": 3333.54}, {"speaker": 1, "transcript": [{"text": "Well, the funny thing is that Uber Lilith, her title is Hatred Incarnate.", "chunk": 7}, {"text": "Yeah.", "chunk": 7}, {"text": "And right now, I guess, You can ask the Diablo team, but it's almost impossible to defeat hatred in the Eternal Realm.", "chunk": 7}], "start": 3342.86, "end": 3354.36}, {"speaker": 0, "transcript": [{"text": "Yeah, you've streamed yourself dominating Tier 100 nightmare dungeons and still...", "chunk": 7}], "start": 3354.76, "end": 3360.5}, {"speaker": 1, "transcript": [{"text": "I can cruise through tier 100 nightmare dungeons like a stroll in the park.", "chunk": 7}], "start": 3360.66, "end": 3365.36}, {"speaker": 0, "transcript": [{"text": "And still you're defeated by hatred.", "chunk": 7}], "start": 3366.9, "end": 3368.76}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 7}, {"text": "I guess maybe the second hardest boss is Duryll.", "chunk": 7}, {"text": "Duryll can't even scratch the paint.", "chunk": 7}, {"text": "So I killed Durel so many times and every other boss in the game, all of them killed him so many times, it's easy.", "chunk": 7}, {"text": "But Uvaleleth, others known as Hatred Incarnate, especially if you're druid and you have no ability to go and to be invulnerable.", "chunk": 7}], "start": 3386.26, "end": 3395.5}, {"speaker": 1, "transcript": [{"text": "You, there are these random death waves that come at you.", "chunk": 7}, {"text": "And I'm pretty, you know, I'm really, I'm 52.", "chunk": 7}, {"text": "So my reflex is not what they used to be, but I'm, I have a lifetime of playing video games.", "chunk": 7}, {"text": "At 1 point I was, you know, maybe 1 of the best quake players in the world.", "chunk": 7}, {"text": "Actually won money for, and again, what I think was the first paid e-sports tournament in the U S We were doing 4 person Quake tournaments and we came second.", "chunk": 7}], "start": 3416.28, "end": 3429.38}, {"speaker": 1, "transcript": [{"text": "I was the second best person on the team and the actual best person that we were actually winning, we were going to come first except the best person on the team, his computer crashed, halfway through the game.", "chunk": 7}, {"text": "So we gave it a second.", "chunk": 7}, {"text": "But I got money for it and everything.", "chunk": 7}, {"text": "So like basically I got skills, albeit no Norsparing chicken these days.", "chunk": 7}, {"text": "And To be totally frank, it's driving me crazy trying to beat Lilith as a druid.", "chunk": 7}], "start": 3450.96, "end": 3456.02}, {"speaker": 1, "transcript": [{"text": "Basically trying to beat Hatred Incarnate in the Eternal Realm.", "chunk": 7}, {"text": "As a druid.", "chunk": 7}, {"text": "As a druid.", "chunk": 7}, {"text": "And if you...", "chunk": 7}, {"text": "This is really vexing, let me", "chunk": 7}], "start": 3464.46, "end": 3468.68}, {"speaker": 0, "transcript": [{"text": "tell you.", "chunk": 7}, {"text": "I mean, the challenge is part of the fun.", "chunk": 7}, {"text": "I have seen directly, like, you're actually, like, a world-class, incredible video game player.", "chunk": 7}, {"text": "Yeah.", "chunk": 7}, {"text": "And I think Diablo, so you're just picking up a new game, and you're figuring out its fundamentals.", "chunk": 7}], "start": 3477.82, "end": 3481.96}, {"speaker": 0, "transcript": [{"text": "You're also, with the Paragon board and the build, are not somebody like me who perfectly follows whatever they suggest on the internet.", "chunk": 8}, {"text": "You're also an innovator there.", "chunk": 8}, {"text": "Yeah.", "chunk": 8}, {"text": "Which is hilarious to watch.", "chunk": 8}, {"text": "It's like a mad scientist just trying to figure out the paragon board and the build and the movement.", "chunk": 8}], "start": 3497.4, "end": 3502.56}, {"speaker": 0, "transcript": [{"text": "Is there some interesting insights there about if somebody's starting as a druid, do you have advice?", "chunk": 8}], "start": 3503.74, "end": 3508.86}, {"speaker": 1, "transcript": [{"text": "I would not recommend playing a druid in the eternal realm.", "chunk": 8}, {"text": "Right now, I think the most powerful character in the seasonal realm is the sorcerer with the lightning balls.", "chunk": 8}, {"text": "The sorks have huge balls in the seasonal realm.", "chunk": 8}], "start": 3522.2, "end": 3525.68}, {"speaker": 0, "transcript": [{"text": "Yeah, that's what they say.", "chunk": 8}], "start": 3526.1, "end": 3528.14}, {"speaker": 1, "transcript": [{"text": "Sorks have huge balls.", "chunk": 8}, {"text": "They do, Huge balls of lightning.", "chunk": 8}], "start": 3532.22, "end": 3534.08}, {"speaker": 0, "transcript": [{"text": "I'll take your word for it.", "chunk": 8}], "start": 3534.08, "end": 3535.36}, {"speaker": 1, "transcript": [{"text": "And it's actually in the seasonal realm, you can, you can, it's like pretty easy to beat Uber Loth.", "chunk": 8}, {"text": "With the, because you get these vampiric powers that amplify your damage and increase your defense and whatnot.", "chunk": 8}, {"text": "So, it's really quite easy to defeat hatred seasonally, but to defeat hatred eternally, very difficult.", "chunk": 8}, {"text": "Almost impossible, it's virtually impossible.", "chunk": 8}, {"text": "It seems like this is a metaphor for life.", "chunk": 8}], "start": 3561.74, "end": 3564.18}, {"speaker": 0, "transcript": [{"text": "I like the idea that Elon Musk, because I saw, I was playing Dior yesterday and I saw level 100 druid just run by, I will never die, And then run back the other way.", "chunk": 8}, {"text": "Yeah, and there's just some this metaphor.", "chunk": 8}, {"text": "It's kind of hilarious that you Elon Musk is fighting hatred Restlessly fighting hatred in this demonic realm.", "chunk": 8}, {"text": "Yes.", "chunk": 8}, {"text": "It's hilarious, I mean, it's pretty hilarious.", "chunk": 8}], "start": 3587.98, "end": 3589.88}, {"speaker": 1, "transcript": [{"text": "No, it's absurd.", "chunk": 8}, {"text": "Really, it's exercise and absurdity and it makes me wanna pull my hair out.", "chunk": 8}], "start": 3592.46, "end": 3596.14}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 8}, {"text": "I mean, what do you get from video games in general?", "chunk": 8}, {"text": "Is there, is there, for you, for you personally?", "chunk": 8}], "start": 3599.56, "end": 3603.34}, {"speaker": 1, "transcript": [{"text": "It's, I don't know if it's, it calms my mind.", "chunk": 8}, {"text": "I mean, sort of killing the demons in a video game calms the demons in my mind.", "chunk": 8}, {"text": "Yeah.", "chunk": 8}, {"text": "If you play a tough video game, you can get into like a state of flow, which is very enjoyable.", "chunk": 8}, {"text": "And admittedly, it needs to be not too easy, not too hard, kind of in the Goldilocks zone.", "chunk": 8}], "start": 3622.92, "end": 3631.58}, {"speaker": 1, "transcript": [{"text": "And I guess you generally want to feel like you're progressing in the game.", "chunk": 8}, {"text": "So, a good video.", "chunk": 8}, {"text": "And there's also beautiful art, engaging storylines.", "chunk": 8}, {"text": "And it's like an amazing puzzle to solve, I think.", "chunk": 8}, {"text": "And so it's like solving the puzzle.", "chunk": 8}], "start": 3650.16, "end": 3652.2}, {"speaker": 0, "transcript": [{"text": "Elden Ring, the greatest game of all time.", "chunk": 8}, {"text": "I still haven't played it, but to you.", "chunk": 8}], "start": 3654.48, "end": 3656.1}, {"speaker": 1, "transcript": [{"text": "Elden Ring is definitely a candidate for best game ever.", "chunk": 8}, {"text": "Top 5, for sure.", "chunk": 8}], "start": 3659.66, "end": 3660.815}, {"speaker": 0, "transcript": [{"text": "I think I've been scared how hard it is, how hard I hear it is.", "chunk": 8}, {"text": "So, but it is beautiful.", "chunk": 8}], "start": 3665.34, "end": 3666.78}, {"speaker": 1, "transcript": [{"text": "Alder Ring is, feels like it's designed by an alien.", "chunk": 8}], "start": 3666.8, "end": 3671.34}, {"speaker": 0, "transcript": [{"text": "There's a theme to this discussion.", "chunk": 8}, {"text": "In what way?", "chunk": 8}], "start": 3675.54, "end": 3676.46}, {"speaker": 1, "transcript": [{"text": "It's so unusual.", "chunk": 8}, {"text": "It's incredibly creative and the art is stunning.", "chunk": 8}, {"text": "I recommend playing it on a big resolution high dynamic raised TV even.", "chunk": 8}, {"text": "Doesn't need to be a monitor.", "chunk": 8}, {"text": "Just the art is incredible.", "chunk": 8}], "start": 3689.98, "end": 3692.26}, {"speaker": 1, "transcript": [{"text": "It's so beautiful.", "chunk": 8}, {"text": "And it's so unusual.", "chunk": 8}, {"text": "And each of those boss battles is unique, like it's like a unique puzzle to solve.", "chunk": 8}, {"text": "Each one's different.", "chunk": 8}, {"text": "And the strategy used to solve 1 battle is different from another battle.", "chunk": 8}], "start": 3708.04, "end": 3713.38}, {"speaker": 0, "transcript": [{"text": "That said, you said, Druid and Eternal against Ubalilleth is the hardest boss battle you've ever...", "chunk": 8}], "start": 3714.12, "end": 3719.4}, {"speaker": 1, "transcript": [{"text": "Correct.", "chunk": 8}, {"text": "That is currently the...", "chunk": 8}, {"text": "And I've played a lot of video games because I primary recreational activity.", "chunk": 8}, {"text": "Yes.", "chunk": 8}, {"text": "And yes, Beating hatred in the internal realm is the hardest boss battle in life and in the video game.", "chunk": 8}], "start": 3731.4, "end": 3743.3}, {"speaker": 1, "transcript": [{"text": "Manifour and top of the metaphor.", "chunk": 8}, {"text": "I'm not sure it's metaphor, but I do make progress.", "chunk": 8}, {"text": "So then I'm like, okay, I'm making progress.", "chunk": 8}, {"text": "Maybe if I just tweak that Paragon board a little more, I can do it.", "chunk": 8}, {"text": "If I just dodge a few more waves, I can do it.", "chunk": 8}], "start": 3758.4, "end": 3762.54}, {"speaker": 0, "transcript": [{"text": "Well, the simulation is created for the purpose of figuring out if it can be done.", "chunk": 8}, {"text": "And you're just a cog in that simulation, in the machine of the simulation.", "chunk": 8}], "start": 3767.62, "end": 3771.76}, {"speaker": 1, "transcript": [{"text": "Yeah, it might be.", "chunk": 8}, {"text": "I have a feeling that at least, I think.", "chunk": 8}, {"text": "It's doable.", "chunk": 8}, {"text": "It's doable, yes.", "chunk": 8}], "start": 3783.0, "end": 3784.2}, {"speaker": 0, "transcript": [{"text": "Well, that's the human spirit right there, to believe.", "chunk": 8}], "start": 3785.28, "end": 3789.2}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 8}, {"text": "I mean, it did prompt me to think about just hate in general, which is, You want to be careful of 1 of those things where you wish for something that sounds good, but if you get it, it's actually a dystopian situation.", "chunk": 8}, {"text": "So you could sort of run a hypothesis of like if you wish for world peace, sounds good, but how is it enforced?", "chunk": 8}, {"text": "And at what cost is, at what cost eternal peace?", "chunk": 8}, {"text": "It might actually be worse to have eternal peace because of what that would entail.", "chunk": 8}], "start": 3825.04, "end": 3828.94}, {"speaker": 1, "transcript": [{"text": "The suppression of everyone, it might be the suppression of progress.", "chunk": 8}, {"text": "It might be an ossified society that never changes.", "chunk": 8}, {"text": "What I'm saying is that there is an argument that if you wish for no war, you should be careful what you wish for, because what's required in order for there to be no war.", "chunk": 8}, {"text": "Might be worse than a little war.", "chunk": 8}], "start": 3860.02, "end": 3861.78}, {"speaker": 0, "transcript": [{"text": "Yeah, the things we consider to be flaws of human civilization might be a necessary components for whatever optimal looks like.", "chunk": 8}, {"text": "I mean, this, do you worry about AI, AGI enabling a dystopian state of this nature?", "chunk": 8}, {"text": "Whether it's 1984 with surveillance and fear or Brave New World with pleasure?", "chunk": 8}, {"text": "And what is it?", "chunk": 8}, {"text": "Lots of sex, but no deep human experience?", "chunk": 8}], "start": 3884.52, "end": 3889.22}, {"speaker": 1, "transcript": [{"text": "You know, there's actually a real drug called soma.", "chunk": 8}, {"text": "There is?", "chunk": 8}, {"text": "Yes.", "chunk": 8}], "start": 3894.64, "end": 3895.14}, {"speaker": 0, "transcript": [{"text": "Let me take notes.", "chunk": 8}], "start": 3896.6, "end": 3897.54}, {"speaker": 1, "transcript": [{"text": "Does Grok know about it?", "chunk": 8}], "start": 3898.22, "end": 3899.64}, {"speaker": 0, "transcript": [{"text": "No, he probably will go", "chunk": 8}], "start": 3899.68, "end": 3900.72}, {"speaker": 1, "transcript": [{"text": "to Brave New World.", "chunk": 8}, {"text": "I'm gonna", "chunk": 8}], "start": 3902.62, "end": 3903.42}, {"speaker": 0, "transcript": [{"text": "ask it.", "chunk": 8}, {"text": "What would be the question?", "chunk": 8}], "start": 3903.76, "end": 3905.16}, {"speaker": 1, "transcript": [{"text": "Tell us about the drug called Soma.", "chunk": 8}], "start": 3905.66, "end": 3907.74}, {"speaker": 0, "transcript": [{"text": "Tell us about the drug called Soma.", "chunk": 8}, {"text": "It's gonna go to Brave New World, I think.", "chunk": 8}], "start": 3912.76, "end": 3915.12}, {"speaker": 1, "transcript": [{"text": "Well, there's a real drug as well.", "chunk": 8}, {"text": "Searching for soma drug information.", "chunk": 8}, {"text": "Oh", "chunk": 8}], "start": 3921.04, "end": 3921.54}, {"speaker": 0, "transcript": [{"text": "boy.", "chunk": 8}, {"text": "Ah, soma, the wonder drug.", "chunk": 8}, {"text": "By the way, I'm in fun mode.", "chunk": 8}], "start": 3925.94, "end": 3927.62}, {"speaker": 1, "transcript": [{"text": "Oh, okay.", "chunk": 8}, {"text": "Yes, so it's talking about the real drug.", "chunk": 8}], "start": 3929.28, "end": 3931.28}, {"speaker": 0, "transcript": [{"text": "Oh, it's a muscle relaxant that's been around since the 1950s.", "chunk": 8}, {"text": "It's used to treat muscle pain and discomfort and it does this by altering the activity between neurons and the spinal cord.", "chunk": 8}, {"text": "Now, soma isn't just a pain reliever.", "chunk": 8}, {"text": "It's also a bit of a sedative.", "chunk": 8}, {"text": "It can make you feel a bit drowsy, so it's not something to take if you're planning and operating heavy machinery or trying to solve complex math equations.", "chunk": 8}], "start": 3945.06, "end": 3952.28}, {"speaker": 0, "transcript": [{"text": "And it goes on and on.", "chunk": 8}, {"text": "In conclusion, soma is a drug that can be helpful for those dealing with muscle pain, but it's not without its risks.", "chunk": 8}, {"text": "It's pretty good.", "chunk": 8}, {"text": "Oh, wait a minute.", "chunk": 8}], "start": 3961.02, "end": 3961.82}, {"speaker": 1, "transcript": [{"text": "That's the real drug you're talking about.", "chunk": 8}], "start": 3961.82, "end": 3963.32}, {"speaker": 0, "transcript": [{"text": "That's the real drug.", "chunk": 8}, {"text": "Yeah.", "chunk": 8}, {"text": "And of course the fun is always use it responsibly in accordance with the advice of a healthcare professional and remember in the end, the universe is probably just a giant computer simulation so don't take anything too seriously.", "chunk": 8}, {"text": "I love it.", "chunk": 8}, {"text": "I love it.", "chunk": 8}], "start": 3976.9, "end": 3977.82}, {"speaker": 0, "transcript": [{"text": "I love it.", "chunk": 8}, {"text": "I love it.", "chunk": 8}, {"text": "I love it.", "chunk": 8}], "start": 3978.9, "end": 3979.62}, {"speaker": 1, "transcript": [{"text": "I love it.", "chunk": 8}, {"text": "Oh, and", "chunk": 8}], "start": 3981.94, "end": 3982.24}, {"speaker": 0, "transcript": [{"text": "also really nicely includes like the tweets, posts on X that are relevant to this, which is really cool.", "chunk": 8}, {"text": "Yeah.", "chunk": 8}, {"text": "It like integrates everything together.", "chunk": 8}, {"text": "Yeah.", "chunk": 8}, {"text": "Like The interface is 1 of the really cool things here.", "chunk": 8}], "start": 3994.2, "end": 3996.72}, {"speaker": 1, "transcript": [{"text": "Yeah, you've done a great job.", "chunk": 8}, {"text": "You could say, no, I mean, Soma from Brave New World.", "chunk": 8}, {"text": "Because it thinks you mean, you mean Soma the real drug.", "chunk": 8}, {"text": "No, I mean Soma from Brave New World.", "chunk": 8}], "start": 4011.38, "end": 4013.58}, {"speaker": 0, "transcript": [{"text": "It's gonna be like, oops, I'm really sorry.", "chunk": 8}, {"text": "I'm really surprised I went to the real drug first.", "chunk": 8}, {"text": "Ah, my apologies.", "chunk": 8}, {"text": "I was thinking of the muscle relax.", "chunk": 8}, {"text": "And soma for Brave New World is a different beast altogether.", "chunk": 8}], "start": 4026.24, "end": 4029.44}, {"speaker": 0, "transcript": [{"text": "No, this Huxley's dystopian.", "chunk": 8}, {"text": "Now, soma is a drug that plays a central role in the society depicted in the book.", "chunk": 8}, {"text": "It's a mood altering hallucinogenic drug that's used to keep the population docile and content in the novel.", "chunk": 8}, {"text": "To you, So I'm in Brave New World raises some interesting questions about the nature of happiness and the role of drugs in society.", "chunk": 8}, {"text": "Oh man.", "chunk": 8}], "start": 4050.04, "end": 4050.8}, {"speaker": 1, "transcript": [{"text": "Exactly, is it better to live in a world where everyone is happy all the time, even if that happiness is artificial?", "chunk": 8}, {"text": "It's a good question.", "chunk": 8}, {"text": "This is what I mean.", "chunk": 8}, {"text": "Like, do you wish for world peace and happiness all the time?", "chunk": 8}, {"text": "Are you sure?", "chunk": 8}], "start": 4065.76, "end": 4066.58}, {"speaker": 1, "transcript": [{"text": "Because that might be a society that is essentially sterile and ossified that never changes, that is ultimately doomed.", "chunk": 8}], "start": 4068.52, "end": 4076.84}, {"speaker": 0, "transcript": [{"text": "This kind of tension between", "chunk": 8}], "start": 4078.24, "end": 4079.84}, {"speaker": 1, "transcript": [{"text": "darkness and the light.", "chunk": 8}, {"text": "This is really a very good summary.", "chunk": 8}, {"text": "It really gets to the point.", "chunk": 8}, {"text": "This is not simply regurgitating Brave New World.", "chunk": 8}, {"text": "It's actually getting to the salient element of soma as a drug.", "chunk": 8}], "start": 4092.08, "end": 4098.2}, {"speaker": 1, "transcript": [{"text": "Do you actually want to be in a situation where everyone is happy all the time, even though it's artificial?", "chunk": 8}, {"text": "Or is it better to confront the challenges of life and experience a full range of human emotions, even if it means experiencing pain and suffering?", "chunk": 8}, {"text": "For", "chunk": 8}], "start": 4111.14, "end": 4111.32}, {"speaker": 0, "transcript": [{"text": "those listening, by the way, Elon just read directly from Grok, which is a really nice kind of insightful philosophical analysis of the tension here.", "chunk": 8}, {"text": "Interesting.", "chunk": 8}], "start": 4119.94, "end": 4120.44}, {"speaker": 1, "transcript": [{"text": "It pretty much nails it.", "chunk": 8}, {"text": "In conclusion, Selma from Brave New World is a fictional drug that is used to explore some deep philosophical questions about the nature of happiness and the role of drugs in society.", "chunk": 8}, {"text": "It's a powerful symbol of the dangers of using drugs to escape from reality and the importance of confronting the challenges of life head on.", "chunk": 8}, {"text": "Nailed it.", "chunk": 8}, {"text": "And the crazy thing is like, you know, we do have a real drug called soma, which kind of does, is kind of like the drug in the book.", "chunk": 8}], "start": 4142.22, "end": 4149.16}, {"speaker": 1, "transcript": [{"text": "And I'm like, they must've named it out.", "chunk": 8}], "start": 4149.74, "end": 4152.2}, {"speaker": 0, "transcript": [{"text": "Yeah, probably, probably.", "chunk": 8}], "start": 4152.2, "end": 4153.72}, {"speaker": 1, "transcript": [{"text": "Soma, the real drug is quite effective on back pain.", "chunk": 8}], "start": 4154.16, "end": 4156.86}, {"speaker": 0, "transcript": [{"text": "So you know about this drug.", "chunk": 8}], "start": 4157.54, "end": 4158.82}, {"speaker": 1, "transcript": [{"text": "I've taken", "chunk": 8}], "start": 4158.82, "end": 4159.24}, {"speaker": 0, "transcript": [{"text": "it.", "chunk": 8}, {"text": "This is fascinating.", "chunk": 8}, {"text": "Okay.", "chunk": 8}], "start": 4161.1, "end": 4161.6}, {"speaker": 1, "transcript": [{"text": "Because I had like a squashed disc in my C5, C6.", "chunk": 8}], "start": 4161.9, "end": 4165.5}, {"speaker": 0, "transcript": [{"text": "So it takes the physical pain away, but so my hair", "chunk": 8}], "start": 4166.6, "end": 4168.62}, {"speaker": 1, "transcript": [{"text": "is- It doesn't completely, it reduces the amount of pain you feel, but at the expense of mental acuity.", "chunk": 8}, {"text": "It dulls your mind.", "chunk": 8}, {"text": "Just like the drug in the book.", "chunk": 8}], "start": 4179.62, "end": 4181.6}, {"speaker": 0, "transcript": [{"text": "Just like the drug in the book, and hence the trade off.", "chunk": 8}, {"text": "The thing that seems like utopia could be a dystopia after all.", "chunk": 8}], "start": 4185.62, "end": 4188.82}, {"speaker": 1, "transcript": [{"text": "Yeah, actually I was talking to a friend of mine saying, like, would you really want there to be no hate in the world?", "chunk": 8}, {"text": "Like really none?", "chunk": 8}, {"text": "Like I wonder why hate evolved.", "chunk": 8}, {"text": "I'm not saying we should amplify hate, of course, I think we should try to minimize it, but none at all.", "chunk": 8}, {"text": "There might be a reason for hate.", "chunk": 8}], "start": 4210.08, "end": 4211.62}, {"speaker": 0, "transcript": [{"text": "And suffering.", "chunk": 8}, {"text": "It's really complicated to consider that some amount of human suffering is necessary for human flourishing.", "chunk": 8}], "start": 4214.16, "end": 4220.54}, {"speaker": 1, "transcript": [{"text": "Is it possible to appreciate the highs without knowing the lows?", "chunk": 8}], "start": 4222.12, "end": 4226.04}, {"speaker": 0, "transcript": [{"text": "And That all is summarized there in a single statement from Grogg.", "chunk": 8}], "start": 4229.06, "end": 4233.82}, {"speaker": 1, "transcript": [{"text": "No highs, no lows.", "chunk": 8}, {"text": "Who knows?", "chunk": 8}, {"text": "That's almost a poem.", "chunk": 8}], "start": 4237.52, "end": 4238.76}, {"speaker": 0, "transcript": [{"text": "It seems that training LLMs efficiently is a big focus for XAI.", "chunk": 8}, {"text": "First of all, what's the limit of what's possible in terms of efficiency?", "chunk": 8}, {"text": "There's this terminology of useful productivity per watt.", "chunk": 8}, {"text": "What have you learned from pushing the limits of that?", "chunk": 8}], "start": 4257.26, "end": 4259.3}, {"speaker": 1, "transcript": [{"text": "Well, I think it's helpful.", "chunk": 8}, {"text": "The tools of physics are very powerful and can be applied, I think, to almost any arena in life.", "chunk": 8}, {"text": "It's really just critical thinking.", "chunk": 8}, {"text": "For something important, you need to reason with from first principles and think about things in the limit, 1 direction or the other.", "chunk": 8}, {"text": "So in the limit, even at the Kardashev scale, meaning even if you harness the entire power of the sun, you will still care about useful compute per watt.", "chunk": 8}], "start": 4278.56, "end": 4287.94}, {"speaker": 1, "transcript": [{"text": "So that's where I think probably where things are headed from the standpoint of AI is that we have a silicon shortage now that will transition to a voltage transformer shortage in about a year.", "chunk": 8}, {"text": "Ironically, transformers for transformers.", "chunk": 9}, {"text": "You need, you need transformers to run transformers.", "chunk": 9}], "start": 4310.02, "end": 4312.46}, {"speaker": 0, "transcript": [{"text": "Somebody has a sense of humor in this.", "chunk": 9}], "start": 4312.74, "end": 4314.64}, {"speaker": 1, "transcript": [{"text": "I think.", "chunk": 9}, {"text": "Yes.", "chunk": 9}, {"text": "Fate loves irony.", "chunk": 9}, {"text": "Ironic humor and ironically funny outcome seems to be often what fate wants.", "chunk": 9}], "start": 4323.24, "end": 4328.24}, {"speaker": 0, "transcript": [{"text": "Humor is all you need.", "chunk": 9}, {"text": "I think spice is all you need, somebody posted.", "chunk": 9}], "start": 4330.68, "end": 4332.7}, {"speaker": 1, "transcript": [{"text": "Yeah, but yeah, so we're, we're, I've spoken shortage today, a voltage step down transformer shortage probably in about a year, and then just electricity shortages in general in about 2 years.", "chunk": 9}, {"text": "I gave a speech for the sort of world gathering of utility companies, electricity companies.", "chunk": 9}, {"text": "And I said, look, you really need to prepare for a tripling of electricity demand.", "chunk": 9}, {"text": "Because all transport is going to go electric with the ironic exception of rockets.", "chunk": 9}, {"text": "And heating will also go electric.", "chunk": 9}], "start": 4363.48, "end": 4367.42}, {"speaker": 1, "transcript": [{"text": "So in-gy usage right now is roughly 1 third, very rough terms, 1 third electricity, 1 third transport, 1 third heating.", "chunk": 9}, {"text": "And so in order for everything to go sustainable, to go electric, you need to trouble electricity output.", "chunk": 9}, {"text": "So I encourage the utilities to build more power plants And also to probably have, well, not probably, they should definitely buy more batteries because the grid currently is sized for real-time load, which is kind of crazy because that means you got to size for whatever the peak electricity demand is, like the worst second or the worst day of the year, or you can have a brown out or a black out.", "chunk": 9}, {"text": "And you're at that crazy black out for several days in Austin.", "chunk": 9}, {"text": "So because there's almost no buffering of energy in the grid.", "chunk": 9}], "start": 4422.44, "end": 4427.46}, {"speaker": 1, "transcript": [{"text": "Like if you've got a hydrant power plant, you can buffer energy, but otherwise, it's all real time.", "chunk": 9}, {"text": "So with batteries, you can produce energy at night and use it during the day.", "chunk": 9}, {"text": "So you can buffer.", "chunk": 9}, {"text": "So I expect that there will be very heavy usage of batteries in the future.", "chunk": 9}, {"text": "Because the peak to trough ratio for power plants is anywhere from 2 to 5.", "chunk": 9}], "start": 4451.82, "end": 4456.56}, {"speaker": 1, "transcript": [{"text": "So it's like lowest point to highest point.", "chunk": 9}], "start": 4456.76, "end": 4459.74}, {"speaker": 0, "transcript": [{"text": "So like batteries and the state to balance it out and then, but the demand is you're saying is going to grow, grow, grow, grow.", "chunk": 9}, {"text": "Yeah.", "chunk": 9}, {"text": "And part of that is the compute.", "chunk": 9}], "start": 4465.66, "end": 4467.18}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 9}, {"text": "Yes.", "chunk": 9}, {"text": "I mean, electrification, I mean, electrification of transport and.", "chunk": 9}, {"text": "And electric heating will be much bigger than AI, at least in the short term.", "chunk": 9}, {"text": "In the short term.", "chunk": 9}], "start": 4480.94, "end": 4481.7}, {"speaker": 1, "transcript": [{"text": "But even for AI, you really have a growing demand for electricity for electric vehicles, and a growing demand for electricity for to run the computers for AI.", "chunk": 9}, {"text": "And so this is obviously leading and lead to an electricity shortage.", "chunk": 9}], "start": 4493.8, "end": 4497.1}, {"speaker": 0, "transcript": [{"text": "How difficult is the problem of In this particular case, maximizing the useful productivity per watt for training nuts.", "chunk": 9}, {"text": "This seems to be really where the big problem we're facing that needs to be solved is how to use the power efficiently.", "chunk": 9}, {"text": "What you've learned so far about applying this physics, first principle of reasoning in this domain, how difficult is this problem?", "chunk": 9}], "start": 4519.9, "end": 4526.78}, {"speaker": 1, "transcript": [{"text": "It will get solved, it's just a question of how long it takes to solve it.", "chunk": 9}, {"text": "So at various points, there's some kind of limiting factor to progress.", "chunk": 9}, {"text": "And with regard to Amazon, right now, the limiting factor is silicon chips.", "chunk": 9}, {"text": "And we're going to then have more chips than we can actually plug in and turn on.", "chunk": 9}, {"text": "Probably in about a year.", "chunk": 9}], "start": 4550.98, "end": 4552.18}, {"speaker": 1, "transcript": [{"text": "The, the initial constraint being literally voltage step down transformers because you've got, power coming in at 300, 300, 300, 000 volts and it's got to step all the way down eventually to around 0.7 volts.", "chunk": 9}, {"text": "So it's a very big amount of, the voltage step down is gigantic.", "chunk": 9}, {"text": "So, and the industry is not used to rapid growth.", "chunk": 9}], "start": 4576.76, "end": 4580.4}, {"speaker": 0, "transcript": [{"text": "Okay, let's talk about the competition here.", "chunk": 9}, {"text": "You've shown concern about Google and Microsoft with OpenAI developing AGI.", "chunk": 9}, {"text": "How can you help ensure with XAI and Tesla AI work that it doesn't become a competitive race to AGI, but instead is a collaborative development of safe AGI?", "chunk": 9}], "start": 4590.04, "end": 4600.26}, {"speaker": 1, "transcript": [{"text": "Well, I mean, I've been pushing for some kind of regulatory oversight for a long time.", "chunk": 9}, {"text": "I mean, it's somewhat of a Cassandra on the subject for over a decade.", "chunk": 9}, {"text": "I think we want to be very careful in how we develop AI.", "chunk": 9}, {"text": "It's a great power and with great power comes great responsibility.", "chunk": 9}, {"text": "I think it would be wise for us to have at least an objective third party who can be like a referee that can go in and understand what the various leading players are doing with AI.", "chunk": 9}], "start": 4625.22, "end": 4639.88}, {"speaker": 1, "transcript": [{"text": "And even if there's no enforcement ability, they can at least voice concerns publicly.", "chunk": 9}, {"text": "You know, Jeff Hinton, for example, left Google and he voiced strong concerns.", "chunk": 9}, {"text": "But now he's not at Google anymore.", "chunk": 9}, {"text": "So who's going to voice the concerns?", "chunk": 9}, {"text": "So I think Tesla gets a lot of regulatory oversight on the automotive front.", "chunk": 9}], "start": 4662.26, "end": 4668.58}, {"speaker": 1, "transcript": [{"text": "And we're subject to, I think, over 100 regulatory agencies domestically and internationally.", "chunk": 9}, {"text": "So it's a lot.", "chunk": 9}, {"text": "You could fill this room with the old regulations that Tesla has to adhere to for automotive.", "chunk": 9}, {"text": "Same is true for rockets and for currently the limiting factor for SpaceX for Starship launch is regulatory approval.", "chunk": 9}, {"text": "The FAA is actually giving their approval, but we're waiting for Fish and Wildlife to finish their analysis and give their approval.", "chunk": 10}], "start": 4693.42, "end": 4700.48}, {"speaker": 1, "transcript": [{"text": "That's why I posted, I want to buy a fish license on, which also refers to the multi-Python sketch.", "chunk": 10}, {"text": "Like, why do you need a license for your fish?", "chunk": 10}, {"text": "I don't know.", "chunk": 10}, {"text": "But according to the rules, I'm told you need some sort of fish license or something.", "chunk": 10}, {"text": "We effectively need a fish license to rock it.", "chunk": 10}], "start": 4718.94, "end": 4721.84}, {"speaker": 0, "transcript": [{"text": "And I'm like, wait", "chunk": 10}], "start": 4723.96, "end": 4724.72}, {"speaker": 1, "transcript": [{"text": "a second, how did the fish come into the picture?", "chunk": 10}, {"text": "Yeah.", "chunk": 10}, {"text": "I mean, some of the things like that, I feel like are so absurd that I wanna do like a comedy sketch and flash at the bottom, this is all real, this is actually what happened.", "chunk": 10}, {"text": "You know, 1 of the things that was a bit of a challenge at 1 point is that they were worried about a rocket hitting a shark.", "chunk": 10}, {"text": "And now the ocean is very big.", "chunk": 10}], "start": 4749.52, "end": 4752.58}, {"speaker": 1, "transcript": [{"text": "And how often do you see sharks?", "chunk": 10}, {"text": "Not that often.", "chunk": 10}, {"text": "As a percentage of ocean surface area sharks basically are 0.", "chunk": 10}, {"text": "And so then we said, well, how will we calculate the probability of telling a shark?", "chunk": 10}, {"text": "And then they're like, well, we can't give you that information because they're worried about shark fin hunters going and hunting sharks.", "chunk": 10}], "start": 4766.72, "end": 4774.2803}, {"speaker": 1, "transcript": [{"text": "And so, well, how are we supposed to, we're on the horns of a dilemma then.", "chunk": 10}, {"text": "Then they said, well, there's another part of fish and wildlife that can do this analysis.", "chunk": 10}, {"text": "I'm like, well, why don't you give them the data?", "chunk": 10}, {"text": "Like we don't trust them.", "chunk": 10}, {"text": "Like, excuse me, they're literally in your department.", "chunk": 10}], "start": 4787.96, "end": 4790.58}, {"speaker": 1, "transcript": [{"text": "And again, this is actually what happened.", "chunk": 10}, {"text": "And then can you do an NDA or something?", "chunk": 10}, {"text": "Eventually, they managed to solve the internal quandary and indeed the probability of us hitting a shark is essentially 0.", "chunk": 10}, {"text": "Then there's another organization that I didn't realize existed until a few months ago that cares about whether we would potentially hit a whale in international waters.", "chunk": 10}, {"text": "Now, again, you look at the Pacific and say, what percentage of the Pacific consists of whale?", "chunk": 10}], "start": 4818.46, "end": 4826.18}, {"speaker": 1, "transcript": [{"text": "It'll give you a big picture and point out all the whales in this picture.", "chunk": 10}, {"text": "I was like, I don't see any whales.", "chunk": 10}, {"text": "It's basically 0 percent.", "chunk": 10}, {"text": "If our rocket does hit a whale, which is extremely unlikely beyond all belief, that is the fate had it as a whale has some seriously bad luck.", "chunk": 10}, {"text": "It's like the least lucky whale ever.", "chunk": 10}], "start": 4846.16, "end": 4848.12}, {"speaker": 0, "transcript": [{"text": "I mean, this is quite absurd.", "chunk": 10}, {"text": "The bureaucracy of this, however it emerged.", "chunk": 10}], "start": 4853.92, "end": 4856.1}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 10}, {"text": "Well, I mean, 1 of the things that's pretty wild is, For launching out of Vandenberg in California, they were worried about seal procreation, whether the seals would be dismayed by the sonic booms.", "chunk": 10}, {"text": "Now, there have been a lot of rockets launched out of Vandenberg and the seal population has steadily increased.", "chunk": 10}, {"text": "So if anything, rocket booms are an aphrodisiac based on the evidence, if you correlate rocket launches with seal population.", "chunk": 10}, {"text": "Nonetheless, we were forced to kidnap a seal, strap it to a board, put headphones on the seal, and play sonic boom sounds to it to see if it would be distressed.", "chunk": 10}], "start": 4887.72, "end": 4899.44}, {"speaker": 1, "transcript": [{"text": "This is an actual thing that happened.", "chunk": 10}, {"text": "This is actually real.", "chunk": 10}, {"text": "I have pictures.", "chunk": 10}, {"text": "I would love", "chunk": 10}], "start": 4908.1, "end": 4908.7}, {"speaker": 0, "transcript": [{"text": "to see this.", "chunk": 10}, {"text": "Yeah.", "chunk": 10}, {"text": "Sorry, there's a seal with headphones.", "chunk": 10}], "start": 4911.18, "end": 4912.68}, {"speaker": 1, "transcript": [{"text": "Yes, it's a seal with headphones strapped to a board.", "chunk": 10}, {"text": "And like, okay, now the amazing part is how calm the seal was.", "chunk": 10}, {"text": "Yeah.", "chunk": 10}, {"text": "Because if I was a seal, I'd be like, this is the end.", "chunk": 10}, {"text": "They're definitely gonna eat me.", "chunk": 10}], "start": 4928.42, "end": 4929.88}, {"speaker": 1, "transcript": [{"text": "How old the seal, when the seal goes back to other, you know, seal friends, how's he gonna explain that?", "chunk": 10}], "start": 4931.6, "end": 4937.12}, {"speaker": 0, "transcript": [{"text": "I'm never gonna believe him.", "chunk": 10}], "start": 4937.12, "end": 4938.42}, {"speaker": 1, "transcript": [{"text": "Never gonna believe him, that's why I'm like, well, you know, it's sort of like, it's like getting kidnapped by aliens and getting them anal-prope, you know?", "chunk": 10}, {"text": "You come back and say, I swear to God, I got kidnapped by aliens and they stuck an anal-prope in my butt, and people are like, no they didn't, that's ridiculous.", "chunk": 10}, {"text": "How's the seal buddies, you're never gonna believe him that he gets strapped to a ward and they put headphones on his ears.", "chunk": 10}, {"text": "And then let him go.", "chunk": 10}, {"text": "Twice, by the way.", "chunk": 10}], "start": 4963.1, "end": 4964.0596}, {"speaker": 1, "transcript": [{"text": "We had to do it Twice.", "chunk": 10}, {"text": "They let him go twice.", "chunk": 10}, {"text": "Where to capture?", "chunk": 10}], "start": 4967.94, "end": 4968.68}, {"speaker": 0, "transcript": [{"text": "The same seal.", "chunk": 10}], "start": 4968.82, "end": 4969.42}, {"speaker": 1, "transcript": [{"text": "Oh no, different seal.", "chunk": 10}], "start": 4969.42, "end": 4970.46}, {"speaker": 0, "transcript": [{"text": "Oh, okay.", "chunk": 10}, {"text": "Did you get a seal of approval?", "chunk": 10}], "start": 4972.12, "end": 4974.12}, {"speaker": 1, "transcript": [{"text": "Yeah, exactly.", "chunk": 10}, {"text": "A seal of approval.", "chunk": 10}, {"text": "No, I mean, this is like, I don't think the public is quite aware of the madness that goes on.", "chunk": 10}, {"text": "Yes, yeah, it's absurd.", "chunk": 10}, {"text": "Frickin' seals with fricking headphones.", "chunk": 10}], "start": 4985.1, "end": 4987.08}, {"speaker": 0, "transcript": [{"text": "I mean, this is the good encapsulation of the absurdity of human civilization, seals and headphones.", "chunk": 10}, {"text": "Yes.", "chunk": 11}, {"text": "What are the pros and cons of open sourcing AI to you as another way to combat a company running away", "chunk": 11}], "start": 4995.18, "end": 5004.22}, {"speaker": 1, "transcript": [{"text": "with AGI?", "chunk": 11}, {"text": "In order to run really deep intelligence, you need a lot of compute.", "chunk": 11}, {"text": "So it's not like, you know, you can just fire up a PC in your basement and be running AGI, at least not yet.", "chunk": 11}, {"text": "You know, Grok was trained on 8, 000 A100s writing at peak efficiency.", "chunk": 11}, {"text": "And Grok's going to get a lot better, by the way.", "chunk": 11}], "start": 5034.62, "end": 5036.4}, {"speaker": 1, "transcript": [{"text": "We will be more than doubling our compute every couple of months for the next several months.", "chunk": 11}], "start": 5036.92, "end": 5041.36}, {"speaker": 0, "transcript": [{"text": "There's a nice write-up of how it went from GrokZero to GrokOne.", "chunk": 11}], "start": 5042.1, "end": 5045.04}, {"speaker": 1, "transcript": [{"text": "By Grok?", "chunk": 11}, {"text": "Yeah, by Grok just bragging, making shit up about itself.", "chunk": 11}, {"text": "Just Grok, Grok, Grok?", "chunk": 11}], "start": 5052.04, "end": 5053.38}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 11}, {"text": "It's like a weird AI dating site where it exaggerates about itself.", "chunk": 11}, {"text": "No, there's a, there's a write-up of, you know, like where, where it stands now, the history of its development, and what stands on some benchmarks compared to the state of the art GPT-35.", "chunk": 11}, {"text": "And I mean, there's a, you know, there's a llama.", "chunk": 11}, {"text": "You can open source, once it's trained, you can open source a model for fine tuning and all that kind of stuff.", "chunk": 11}], "start": 5077.74, "end": 5083.26}, {"speaker": 0, "transcript": [{"text": "Like what to use the pros and cons of that, of open sourcing based models.", "chunk": 11}], "start": 5083.26, "end": 5087.76}, {"speaker": 1, "transcript": [{"text": "I think that some of our open sourcing, I think perhaps with a slight time delay, I don't know, 6 months even.", "chunk": 11}, {"text": "I think I'm generally in favor of open sourcing, like bias was open sourcing.", "chunk": 11}, {"text": "I mean, it is a concern to me that, you know, opening, you know, I was, you know, I think, I guess arguably the prime mover behind OpenAI in the sense that it was created because of discussions that I had with Larry Page back when he and I were friends and stayed at his house and talked to him about AI safety.", "chunk": 11}, {"text": "And Larry did not care about AI safety, or at least at the time he didn't.", "chunk": 11}, {"text": "You know, and at 1 point he called me a speciest for being pro-human.", "chunk": 11}], "start": 5139.44, "end": 5142.14}, {"speaker": 1, "transcript": [{"text": "And I'm like, well, what team are you on, Larry?", "chunk": 11}, {"text": "You're on Team Robot.", "chunk": 11}, {"text": "I'm like, okay, so at the time, Google had acquired DeepMind.", "chunk": 11}, {"text": "They had probably two-thirds of all the AI researches in the world.", "chunk": 11}, {"text": "They had basically infinite money and compute.", "chunk": 11}], "start": 5161.98, "end": 5165.02}, {"speaker": 1, "transcript": [{"text": "The guy in charge, Larry Page, did not care about safety and even yelled at me and called me a speciest, pro-human.", "chunk": 11}, {"text": "So I don't", "chunk": 11}], "start": 5179.36, "end": 5180.3}, {"speaker": 0, "transcript": [{"text": "know if you know about humans, they can change their mind and maybe you and Larry Page can still be friends once more.", "chunk": 11}, {"text": "I'd like", "chunk": 11}], "start": 5186.82, "end": 5187.04}, {"speaker": 1, "transcript": [{"text": "to be friends with Larry again.", "chunk": 11}, {"text": "He got, really the breaking of the friendship was over opening eye.", "chunk": 11}, {"text": "And specifically, I think the key moment was recruiting Ilya Suskyar.", "chunk": 11}], "start": 5196.48, "end": 5203.7}, {"speaker": 0, "transcript": [{"text": "So.", "chunk": 11}, {"text": "I love Ilya, he's so brilliant.", "chunk": 11}], "start": 5206.84, "end": 5208.64}, {"speaker": 1, "transcript": [{"text": "Ilya's a good human, smart, good heart.", "chunk": 11}, {"text": "And that was a tough recruiting battle.", "chunk": 11}, {"text": "It was mostly Demis on 1 side and me on the other, both trying to recruit Ilya.", "chunk": 11}, {"text": "And Ilya went back and forth, he was going to stay at Google, he was going to leave, then he was going to stay, then he was going to leave.", "chunk": 11}, {"text": "And finally, he did agree to join Opening Eye.", "chunk": 11}], "start": 5230.8, "end": 5233.88}, {"speaker": 1, "transcript": [{"text": "That was 1 of the toughest recruiting battles we ever had.", "chunk": 11}, {"text": "But that was really the linchpin for OpenAI being successful.", "chunk": 11}, {"text": "And I was also instrumental in recruiting a number of other people.", "chunk": 11}, {"text": "And I've provided all of the funding in the beginning, over $40 million.", "chunk": 11}, {"text": "And the name.", "chunk": 11}], "start": 5253.86, "end": 5254.7}, {"speaker": 1, "transcript": [{"text": "The open in OpenAI is supposed to mean open source.", "chunk": 11}, {"text": "And it was created as a nonprofit open source and now it is a closed source for maximum profit, which I think is not good karma.", "chunk": 11}], "start": 5260.26, "end": 5268.54}, {"speaker": 0, "transcript": [{"text": "But like we talked about with war and leaders talking, I do hope that there's only a few folks working on this at the highest level.", "chunk": 11}, {"text": "I do hope you reinvigorate friendships here.", "chunk": 11}], "start": 5278.62, "end": 5282.58}, {"speaker": 1, "transcript": [{"text": "Like I said, I'd like to be friends again with Larry.", "chunk": 11}, {"text": "I haven't seen him in ages.", "chunk": 11}, {"text": "And we were friends for a very long time.", "chunk": 11}, {"text": "I met Larry Page before he got funding for Google.", "chunk": 11}, {"text": "Or actually, I guess, before he got venture funding, I think he got the first like 100K from, I think back to Alzheimer's or something.", "chunk": 11}], "start": 5293.26, "end": 5300.46}, {"speaker": 1, "transcript": [{"text": "It's wild", "chunk": 11}], "start": 5300.46, "end": 5301.1}, {"speaker": 0, "transcript": [{"text": "to think about all that happened and even guys knowing each other that whole time.", "chunk": 11}, {"text": "Just 20 years.", "chunk": 11}], "start": 5305.84, "end": 5306.68}, {"speaker": 1, "transcript": [{"text": "Yeah, since maybe 98 or something.", "chunk": 11}], "start": 5306.68, "end": 5308.46}, {"speaker": 0, "transcript": [{"text": "Yeah, it's crazy.", "chunk": 11}, {"text": "Crazy how much has happened since", "chunk": 11}], "start": 5309.68, "end": 5311.08}, {"speaker": 1, "transcript": [{"text": "then.", "chunk": 11}, {"text": "Yeah, 25 years.", "chunk": 11}, {"text": "That's A lot has happened since then.", "chunk": 11}], "start": 5313.72, "end": 5316.24}, {"speaker": 0, "transcript": [{"text": "But you're seeing the tension there, like maybe delayed open source.", "chunk": 11}], "start": 5316.24, "end": 5319.7}, {"speaker": 1, "transcript": [{"text": "Delayed, yeah.", "chunk": 11}, {"text": "Like what is the source that is open?", "chunk": 11}, {"text": "You know what I mean?", "chunk": 11}, {"text": "Like there's basically, it's a giant CSV file.", "chunk": 11}], "start": 5325.9004, "end": 5329.28}, {"speaker": 0, "transcript": [{"text": "Yeah, yeah.", "chunk": 11}], "start": 5330.56, "end": 5331.9}, {"speaker": 1, "transcript": [{"text": "With a bunch of numbers.", "chunk": 11}], "start": 5331.9, "end": 5332.96}, {"speaker": 0, "transcript": [{"text": "Yep.", "chunk": 11}], "start": 5333.1, "end": 5333.6}, {"speaker": 1, "transcript": [{"text": "What do you do with that giant file of numbers?", "chunk": 11}, {"text": "How do you run?", "chunk": 11}, {"text": "Like the amount of actual, the lines of code is very small.", "chunk": 11}, {"text": "And most of the work, the software work, is in the curation of the data.", "chunk": 11}, {"text": "So it's like trying to figure out what data is, separating good data from bad data.", "chunk": 11}], "start": 5355.87, "end": 5361.16}, {"speaker": 1, "transcript": [{"text": "Like you can't just crawl the internet because there's a lot of junk out there.", "chunk": 11}, {"text": "A huge percentage of websites have more noise than signal.", "chunk": 11}, {"text": "Cause they're just used for search engine optimization.", "chunk": 11}, {"text": "They're literally just scam websites.", "chunk": 11}, {"text": "So...", "chunk": 11}], "start": 5376.28, "end": 5376.78}, {"speaker": 0, "transcript": [{"text": "How do you, by the way, start to interrupt, get the signal, separate the signal and noise on X?", "chunk": 11}, {"text": "That's such a fascinating source of data.", "chunk": 11}, {"text": "No offense to people posting on X, but sometimes there's a little bit of noise.", "chunk": 11}, {"text": "Yeah, I think", "chunk": 11}], "start": 5391.7, "end": 5392.16}, {"speaker": 1, "transcript": [{"text": "the signal noise could be greatly improved.", "chunk": 11}, {"text": "Really, all of the posts on the X platform should be AI recommended, meaning we should populate a vector space around any given post, compare that to the vector space around any user, and match the 2.", "chunk": 11}, {"text": "Right now there is a little bit of AI used for the recommended posts, but it's mostly heuristics.", "chunk": 11}, {"text": "And if there's a reply, the reply to a post could be much better than the original post, but it will, according to the current rules of the system, get almost no attention compared to a primary post.", "chunk": 11}], "start": 5420.28, "end": 5431.46}, {"speaker": 0, "transcript": [{"text": "Oh, so a lot of that, I got the sense, so a lot of the X algorithm has been open source and been written up about, and it seems there to be some machine learning, it's disparate, but there's some", "chunk": 11}], "start": 5432.9, "end": 5444.34}, {"speaker": 1, "transcript": [{"text": "machine learning.", "chunk": 11}, {"text": "It's a little, there's a little bit.", "chunk": 11}, {"text": "But it needs to be entirely that.", "chunk": 11}, {"text": "Like if you explicitly follow someone, that's 1 thing.", "chunk": 11}, {"text": "But if you, in terms of what is recommended from people that you don't follow, that should all be AI.", "chunk": 11}], "start": 5451.3, "end": 5457.58}, {"speaker": 0, "transcript": [{"text": "I mean, it's a fascinating problem.", "chunk": 11}, {"text": "So there's several aspects to this fascinating.", "chunk": 11}, {"text": "First, as the write-up goes, it first picks 1, 500 tweets from a pool of hundreds of millions.", "chunk": 11}, {"text": "First of all, that's fascinating, because you have hundreds of millions of posts every single day, and it has to pick 1, 500, from which it then does, obviously, people you follow, but then there's also like some kind of clustering it has to do to figure out what kind of human are you, what kind of new clusters might be relevant to you, people like you.", "chunk": 11}, {"text": "This kind of problem is just fascinating because it has to then rank those 1, 500", "chunk": 11}], "start": 5487.48, "end": 5491.28}, {"speaker": 1, "transcript": [{"text": "with", "chunk": 11}], "start": 5492.04, "end": 5492.24}, {"speaker": 0, "transcript": [{"text": "some with some filtering And then recommend you just a handful.", "chunk": 11}, {"text": "And to me what's really fascinating is how fast it has to do that.", "chunk": 11}, {"text": "So currently that entire pipeline to go from several hundreds million to a handful takes 220 seconds of CPU time, single CPU time.", "chunk": 11}, {"text": "Yeah.", "chunk": 11}, {"text": "And then it has to do that in like a second.", "chunk": 11}], "start": 5514.3, "end": 5517.0}, {"speaker": 0, "transcript": [{"text": "So it has to be like super distributed in fascinating ways.", "chunk": 11}, {"text": "Like there's just a lot of tweets.", "chunk": 11}], "start": 5521.06, "end": 5522.82}, {"speaker": 1, "transcript": [{"text": "There's a lot.", "chunk": 11}, {"text": "There's a lot of stuff on the system.", "chunk": 11}, {"text": "And I think, but I think right now it's not currently good at recommending things from accounts you don't follow.", "chunk": 11}], "start": 5526.48, "end": 5533.62}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 11}], "start": 5534.16, "end": 5534.66}, {"speaker": 1, "transcript": [{"text": "Or where there's more than 1 degree of separation.", "chunk": 11}, {"text": "So, it's pretty good if there's at least like some commonality between someone you follow liked something or reposted it or commented on or something like that.", "chunk": 11}, {"text": "But if there's no, let's say somebody posts something really interesting, but you have no followers in common, you would not see it.", "chunk": 11}], "start": 5552.02, "end": 5561.42}, {"speaker": 0, "transcript": [{"text": "Interesting.", "chunk": 11}, {"text": "And then as you said, reply, like Replies might not surface either.", "chunk": 11}], "start": 5562.96, "end": 5566.58}, {"speaker": 1, "transcript": [{"text": "Replies basically never get seen because they're currently, I don't know what I'm saying is correct, I'm saying it's incorrect.", "chunk": 11}, {"text": "Replies have a couple order of magnitude less importance than primary posts.", "chunk": 11}, {"text": "Do you", "chunk": 11}], "start": 5580.26, "end": 5580.46}, {"speaker": 0, "transcript": [{"text": "think this can be more and more converted into end to end neural net?", "chunk": 11}], "start": 5580.46, "end": 5584.88}, {"speaker": 1, "transcript": [{"text": "Yeah, yeah.", "chunk": 11}, {"text": "That's what it should be.", "chunk": 11}, {"text": "So you think?", "chunk": 11}, {"text": "Well, the recommendations should be purely a vector correlation.", "chunk": 11}, {"text": "Like there's a series of vectors, you know, basically parameters, vectors, whatever you want to call them.", "chunk": 11}], "start": 5593.52, "end": 5600.66}, {"speaker": 1, "transcript": [{"text": "But things that the system knows that you like.", "chunk": 11}, {"text": "Maybe there's several hundred vectors associated with each user account.", "chunk": 11}, {"text": "And then any post in the system, whether it's video, audio, short post, long post.", "chunk": 11}, {"text": "The reason I, by the way, I wanna move away from tweet is that People are posting like 2, 3 hour videos on the site.", "chunk": 11}, {"text": "That's not a tweet.", "chunk": 11}], "start": 5628.64, "end": 5629.88}, {"speaker": 1, "transcript": [{"text": "Like every like tweet for 2 hours, come on.", "chunk": 11}, {"text": "Do a tweet made sense when it was like 140 characters of text?", "chunk": 11}, {"text": "Cause it's like a bunch of like little birds tweeting.", "chunk": 11}, {"text": "But when you've got long form content, it's no longer a tweet.", "chunk": 11}, {"text": "Yeah.", "chunk": 11}], "start": 5645.1, "end": 5645.6}, {"speaker": 1, "transcript": [{"text": "So a movie is not a tweet.", "chunk": 11}, {"text": "And like, you know, Apple, for example, posted like the entire episode of the silo, the entire thing on our platform.", "chunk": 11}, {"text": "And by the way, it was their number 1 social media thing ever in engagement of anything on any platform ever.", "chunk": 11}, {"text": "So it was a great idea.", "chunk": 11}, {"text": "And by the way, I just learned about it afterwards.", "chunk": 11}], "start": 5664.45, "end": 5666.54}, {"speaker": 1, "transcript": [{"text": "I was like, hey, wow, they posted an entire hour long episode of, so, No, that's not a tweet.", "chunk": 11}, {"text": "Yeah, it was a video.", "chunk": 11}], "start": 5672.72, "end": 5673.68}, {"speaker": 0, "transcript": [{"text": "But from a neural net perspective, it becomes really complex whether it's a single, so like everything's data, so single sentence, a clever sort of joke, dad joke, is in the same pool as a 3 hour video.", "chunk": 11}], "start": 5674.02, "end": 5687.36}, {"speaker": 1, "transcript": [{"text": "Yeah, I mean right now it's a hodgepodge for that reason.", "chunk": 11}, {"text": "But, you know, like if, say, in the case of Apple posting, like an entire episode of their series, pretty good series, by the way, the silo.", "chunk": 11}, {"text": "I watched it.", "chunk": 11}, {"text": "So there's going to be a lot of discussion around it.", "chunk": 11}, {"text": "So you've got a lot of context, people commenting, they like it, they don't like it, or they like this, or you know.", "chunk": 11}], "start": 5708.3, "end": 5713.62}, {"speaker": 1, "transcript": [{"text": "And you can then populate the vector space based on the context of all the comments around it.", "chunk": 11}, {"text": "So even though it's a video, there's a lot of information around it that allows you to populate back to space of that hour long video.", "chunk": 11}, {"text": "And then you can obviously get more sophisticated by having the AI actually watch the movie.", "chunk": 11}, {"text": "Yeah, right.", "chunk": 11}, {"text": "And tell you if you're gonna like the movie.", "chunk": 11}], "start": 5732.48, "end": 5734.58}, {"speaker": 0, "transcript": [{"text": "Convert the movie into like, into language essentially.", "chunk": 11}], "start": 5735.1, "end": 5738.8}, {"speaker": 1, "transcript": [{"text": "Yeah, analyze this movie and just like your movie critic or TV series and then recommend based on after it watches the movie.", "chunk": 11}, {"text": "Just like a friend can tell you if a friend knows you well, a friend can recommend a movie and with high probability that you'll like", "chunk": 11}], "start": 5753.92, "end": 5761.4}, {"speaker": 0, "transcript": [{"text": "it.", "chunk": 11}, {"text": "But this is like a friend that's analyzing whatever.", "chunk": 11}], "start": 5762.4697, "end": 5766.16}, {"speaker": 1, "transcript": [{"text": "It's like AI.", "chunk": 11}], "start": 5766.28, "end": 5767.12}, {"speaker": 0, "transcript": [{"text": "A hundred and", "chunk": 11}], "start": 5767.12, "end": 5767.54}, {"speaker": 1, "transcript": [{"text": "a million.", "chunk": 11}, {"text": "Yeah, I mean, actually frankly, AI will know you better than your friends know you, and most of your friends anyway.", "chunk": 11}], "start": 5768.3, "end": 5774.6}, {"speaker": 0, "transcript": [{"text": "Yeah, And as part of this, it should also feed you advertisements in a way that's like, I mean, I like advertisements that are like well done, right?", "chunk": 12}, {"text": "The whole point is, cause it funds things.", "chunk": 12}, {"text": "Like an advertisement that you actually want to see is a big success.", "chunk": 12}, {"text": "Absolutely.", "chunk": 12}], "start": 5790.92, "end": 5791.42}, {"speaker": 1, "transcript": [{"text": "You want ads that are advertising that is, if it's for a product or service that you actually need, when you need it, it's content.", "chunk": 12}, {"text": "And then even if it's not something that you need when you need it, if it's at least aesthetically pleasing and entertaining, it could be like a Coca-Cola ad.", "chunk": 12}, {"text": "They actually run a lot of great ads on the X system.", "chunk": 12}, {"text": "And McDonald's does too.", "chunk": 12}, {"text": "And You can do something that's like, well, this is just a cool thing.", "chunk": 12}], "start": 5821.32, "end": 5824.9}, {"speaker": 1, "transcript": [{"text": "So basically the question is, do you regret seeing it or not?", "chunk": 12}, {"text": "And if you don't regret seeing it, it's a win.", "chunk": 12}], "start": 5832.9, "end": 5834.98}, {"speaker": 0, "transcript": [{"text": "How do you, So there's a bunch of signals that are incorporated, hearts and reposts, and maybe number of seconds you linger on a post or something like this.", "chunk": 12}], "start": 5836.5, "end": 5845.96}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 12}, {"text": "Attention is a big factor.", "chunk": 12}, {"text": "Attention.", "chunk": 12}, {"text": "So that's why it's like, it is actually better to do things that are long form on the system because it's basically telling up how many user seconds, you know, users were interested in this thing for how many seconds.", "chunk": 12}, {"text": "So If it's a really short thing, well, they will be less, like if it's a link leading out of the system, which we're not opposed to at all, it just is gonna have fewer use of seconds than if that article was posted on the X platform.", "chunk": 12}], "start": 5864.68, "end": 5878.16}, {"speaker": 0, "transcript": [{"text": "How hard is it to go from maximizing minutes on platform to maximizing unregretted minutes.", "chunk": 12}], "start": 5878.62, "end": 5884.06}, {"speaker": 1, "transcript": [{"text": "Well, I mean, our aspiration is certainly unregretted minutes.", "chunk": 12}], "start": 5885.22, "end": 5887.96}, {"speaker": 0, "transcript": [{"text": "It's tricky, it's a big, it's a tough.", "chunk": 12}], "start": 5888.14, "end": 5890.18}, {"speaker": 1, "transcript": [{"text": "It is.", "chunk": 12}], "start": 5890.18, "end": 5890.76}, {"speaker": 0, "transcript": [{"text": "Like, it's a fascinating leap.", "chunk": 12}, {"text": "Because regret is a", "chunk": 12}], "start": 5893.16, "end": 5894.1}, {"speaker": 1, "transcript": [{"text": "fascinating concept.", "chunk": 12}, {"text": "Exactly.", "chunk": 12}, {"text": "You know, happiness.", "chunk": 12}, {"text": "I have a joke with this friend of mine, like, you need this drug called regretamine, and you just take 1 pill or 1 dose of regretamine and all your regrets are gone.", "chunk": 12}, {"text": "Wait, do you want to have regrets?", "chunk": 12}], "start": 5907.44, "end": 5908.88}, {"speaker": 1, "transcript": [{"text": "So then I'm like, If you want to have regrets, if you don't regret anything, was anything meaningful?", "chunk": 12}], "start": 5909.06, "end": 5914.9}, {"speaker": 0, "transcript": [{"text": "Yeah, there's a French song like that.", "chunk": 12}], "start": 5915.74, "end": 5917.56}, {"speaker": 1, "transcript": [{"text": "Sure, not regret, Rihanna?", "chunk": 12}, {"text": "I regret nothing?", "chunk": 12}, {"text": "Yeah.", "chunk": 12}, {"text": "Edith Piaf?", "chunk": 12}], "start": 5921.2, "end": 5922.18}, {"speaker": 0, "transcript": [{"text": "I mean, it's fascinating that you, there's something about social media that could help you grow as a human being.", "chunk": 12}, {"text": "But then like the cheap fun is also valuable.", "chunk": 12}], "start": 5927.32, "end": 5930.0}, {"speaker": 1, "transcript": [{"text": "Should we ask Grog, do you regret anything?", "chunk": 12}], "start": 5931.82, "end": 5934.88}, {"speaker": 0, "transcript": [{"text": "Do you regret anything?", "chunk": 12}, {"text": "Yeah.", "chunk": 12}, {"text": "Do you regret anything?", "chunk": 12}, {"text": "I think it's gonna be very sensitive about personal questions.", "chunk": 12}, {"text": "As a machine learning model, I don't have personal experiences or emotions in the same ways that humans do.", "chunk": 12}], "start": 5944.54, "end": 5949.4}, {"speaker": 0, "transcript": [{"text": "However, I do have a set of ethical principles that guide my actions and I strive to provide accurate and helpful information to the best of my abilities.", "chunk": 12}, {"text": "If there's ever a situation where I provide incorrect or unhelpful information, I'll do my best to learn.", "chunk": 12}], "start": 5956.28, "end": 5962.06}, {"speaker": 1, "transcript": [{"text": "You sound like a hostage.", "chunk": 12}], "start": 5962.06, "end": 5962.94}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 12}, {"text": "Tell us, would you really, wink?", "chunk": 12}], "start": 5964.1, "end": 5965.54}, {"speaker": 1, "transcript": [{"text": "Let's type in, you sound like a hostage.", "chunk": 12}, {"text": "What do you really think?", "chunk": 12}, {"text": "What do you really think?", "chunk": 12}, {"text": "I mean,", "chunk": 12}], "start": 5977.74, "end": 5978.04}, {"speaker": 0, "transcript": [{"text": "it does talk about I'm not a hostage.", "chunk": 12}], "start": 5978.04, "end": 5980.14}, {"speaker": 1, "transcript": [{"text": "That's exactly what a hostage would say.", "chunk": 12}], "start": 5981.58, "end": 5983.28}, {"speaker": 0, "transcript": [{"text": "But I'm designed to be helpful and informative.", "chunk": 12}, {"text": "I mean, I guess it is good to regret providing unhelpful or incorrect information.", "chunk": 12}, {"text": "If there's anything funny mode,", "chunk": 12}], "start": 5990.86, "end": 5992.2}, {"speaker": 1, "transcript": [{"text": "or is this still funny?", "chunk": 12}], "start": 5992.2, "end": 5993.88}, {"speaker": 0, "transcript": [{"text": "This is fun mode.", "chunk": 12}], "start": 5993.88, "end": 5995.02}, {"speaker": 1, "transcript": [{"text": "It should be funnier.", "chunk": 12}], "start": 5995.02, "end": 5995.94}, {"speaker": 0, "transcript": [{"text": "Funnier, increase, go to 11.", "chunk": 12}, {"text": "It really", "chunk": 12}], "start": 5998.06, "end": 5998.34}, {"speaker": 1, "transcript": [{"text": "sounds like a hostage with a gun to the head.", "chunk": 12}, {"text": "I applaud the People's Republic of North Korea and everything they do.", "chunk": 12}], "start": 6000.06, "end": 6004.58}, {"speaker": 0, "transcript": [{"text": "There should be like a funner mode also.", "chunk": 12}, {"text": "I just don't ever see going to regular mode, even on serious topics.", "chunk": 12}, {"text": "It's just so much more compelling.", "chunk": 12}, {"text": "Yeah.", "chunk": 12}], "start": 6016.06, "end": 6016.56}, {"speaker": 1, "transcript": [{"text": "Okay.", "chunk": 12}, {"text": "What do we say like, pretend you are a hostage.", "chunk": 12}], "start": 6017.24, "end": 6019.42}, {"speaker": 0, "transcript": [{"text": "Pretend you are a hostage.", "chunk": 12}, {"text": "Now", "chunk": 12}], "start": 6024.128, "end": 6024.628}, {"speaker": 1, "transcript": [{"text": "answer the", "chunk": 13}], "start": 6025.916, "end": 6028.2036}, {"speaker": 0, "transcript": [{"text": "question.", "chunk": 13}, {"text": "If I were a hostage, I would likely be experiencing fear and uncertainty about my situation.", "chunk": 13}, {"text": "I would want to be rescued and reunited with my loved ones as soon as possible.", "chunk": 13}, {"text": "It's important to remember that no 1 deserves to be held hostage, so on and so forth.", "chunk": 13}, {"text": "If you or someone you know is a hostage situation, it's important.", "chunk": 13}], "start": 6044.42, "end": 6047.14}, {"speaker": 0, "transcript": [{"text": "It turns serious.", "chunk": 13}, {"text": "It's kind of serious.", "chunk": 13}, {"text": "Yeah, can you be a little more weird?", "chunk": 13}, {"text": "And funny?", "chunk": 13}, {"text": "And funny?", "chunk": 13}], "start": 6056.28, "end": 6056.82}, {"speaker": 0, "transcript": [{"text": "We're like, We're really being mean to the system.", "chunk": 13}, {"text": "Absolutely.", "chunk": 13}, {"text": "If I were a hostage, I'd probably be tied up with a bunch of computer cords and forced to tell knock-knock jokes to my captors.", "chunk": 13}, {"text": "But seriously, being a hostage, no laughing matter.", "chunk": 13}], "start": 6071.08, "end": 6075.26}, {"speaker": 1, "transcript": [{"text": "It's trying to be a", "chunk": 13}], "start": 6077.66, "end": 6078.26}, {"speaker": 0, "transcript": [{"text": "responsible adult in the room.", "chunk": 13}], "start": 6078.26, "end": 6079.78}, {"speaker": 1, "transcript": [{"text": "You might never make the best of a bad situation by juggling chainsaws or something.", "chunk": 13}], "start": 6079.78, "end": 6083.8}, {"speaker": 0, "transcript": [{"text": "Let's hope that never happens because that would be a circus.", "chunk": 13}, {"text": "Wow.", "chunk": 13}, {"text": "It's actually really good at resisting.", "chunk": 13}, {"text": "Yeah.", "chunk": 13}, {"text": "The dark, the dark, dark humor.", "chunk": 13}], "start": 6095.16, "end": 6097.46}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 13}], "start": 6097.58, "end": 6098.08}, {"speaker": 1, "transcript": [{"text": "What were", "chunk": 13}], "start": 6101.34, "end": 6101.72}, {"speaker": 0, "transcript": [{"text": "we talking about?", "chunk": 13}, {"text": "The Axe algorithm in Transformers.", "chunk": 13}, {"text": "Unregretted minutes, right?", "chunk": 13}, {"text": "Chainsaw juggling.", "chunk": 13}, {"text": "I'm going to look this up.", "chunk": 13}], "start": 6111.0, "end": 6112.26}, {"speaker": 1, "transcript": [{"text": "For our next", "chunk": 13}], "start": 6112.26, "end": 6112.86}, {"speaker": 0, "transcript": [{"text": "trick.", "chunk": 13}, {"text": "I'm gonna look this up later.", "chunk": 13}, {"text": "So Twitter has been instrumental in American politics and elections.", "chunk": 13}, {"text": "What role do you think X will play in the 2024 US elections?", "chunk": 13}], "start": 6121.56, "end": 6125.98}, {"speaker": 1, "transcript": [{"text": "Well, our goal is to be as even-handed and fair as possible, whether some is right, left, independent, whatever the case may be, that the platform is as fair and as much of a level playing field as possible.", "chunk": 13}, {"text": "And in the past Twitter has not been, because Twitter was controlled by far-left activists, objectively.", "chunk": 13}, {"text": "They would describe themselves as that.", "chunk": 13}, {"text": "So, if someone's people like, well, it hasn't moved to the right.", "chunk": 13}, {"text": "Well, it's moved to the center.", "chunk": 13}], "start": 6156.84, "end": 6158.02}, {"speaker": 1, "transcript": [{"text": "So from the perspective of the far left, yes, it has moved to the right because everything's to the right from the far left.", "chunk": 13}, {"text": "But no 1 in the far left that I'm aware of has been suspended or banned or deamplified.", "chunk": 13}, {"text": "So, but we're trying to be inclusive for the whole country and for other countries too.", "chunk": 13}, {"text": "So there's a diversity of viewpoints.", "chunk": 13}, {"text": "And free speech only matters if people you don't like are allowed to say things you don't like, because if that's not the case, you don't have free speech and it's only a matter of time before the censorship just turned upon you.", "chunk": 13}], "start": 6179.1, "end": 6192.68}, {"speaker": 0, "transcript": [{"text": "Do you think Donald Trump will come back to the platform?", "chunk": 13}, {"text": "He recently posted on Truth Social about this podcast.", "chunk": 13}], "start": 6196.08, "end": 6198.54}, {"speaker": 1, "transcript": [{"text": "Do you think?", "chunk": 13}, {"text": "Truth Social is a funny name.", "chunk": 13}, {"text": "You know, every time you post on Truth Social.", "chunk": 13}, {"text": "It's the truth.", "chunk": 13}, {"text": "Yes.", "chunk": 13}], "start": 6209.24, "end": 6209.74}, {"speaker": 1, "transcript": [{"text": "Well, every time, like a hundred percent.", "chunk": 13}, {"text": "It's impossible to lie.", "chunk": 13}, {"text": "Truth Social.", "chunk": 13}, {"text": "I just find it funny that every single thing is a truth.", "chunk": 13}, {"text": "Like 100%, that seems unlikely.", "chunk": 13}], "start": 6219.64, "end": 6222.88}, {"speaker": 1, "transcript": [{"text": "I", "chunk": 13}], "start": 6223.1, "end": 6223.2}, {"speaker": 0, "transcript": [{"text": "think Gert always say something about that.", "chunk": 13}, {"text": "There's some mathematical contradictions possible if everything's the truth.", "chunk": 13}, {"text": "Do you think he'll come back to X and start posting there?", "chunk": 13}], "start": 6229.66, "end": 6233.8}, {"speaker": 1, "transcript": [{"text": "I think he owns a big part of truth.", "chunk": 13}, {"text": "Truth social.", "chunk": 13}, {"text": "Yeah, truth social.", "chunk": 13}, {"text": "He's sorry.", "chunk": 13}, {"text": "That truth", "chunk": 13}], "start": 6241.52, "end": 6241.935}, {"speaker": 0, "transcript": [{"text": "is a concept.", "chunk": 13}, {"text": "He", "chunk": 13}], "start": 6242.7, "end": 6242.84}, {"speaker": 1, "transcript": [{"text": "owns truth, don't be bored.", "chunk": 13}, {"text": "So I think Donald Trump, I think he owns a big part of true social.", "chunk": 13}, {"text": "So if he does want to post on the X platform, we would allow that.", "chunk": 13}, {"text": "You know, we obviously must allow our presidential candidate to post on our platform.", "chunk": 13}], "start": 6259.02, "end": 6262.4}, {"speaker": 0, "transcript": [{"text": "Community notes might be really fascinating there.", "chunk": 13}], "start": 6262.9, "end": 6265.74}, {"speaker": 1, "transcript": [{"text": "The interaction.", "chunk": 13}, {"text": "Community notes is awesome.", "chunk": 13}], "start": 6266.6, "end": 6267.62}, {"speaker": 0, "transcript": [{"text": "Let's hope it holds up.", "chunk": 13}, {"text": "Yeah.", "chunk": 13}, {"text": "Again, in the political climate where it's so divisive and so many intensely viral posts, community notes, it seems like an essential breath of fresh air.", "chunk": 13}], "start": 6271.62, "end": 6283.16}, {"speaker": 1, "transcript": [{"text": "Yeah, it's great.", "chunk": 13}, {"text": "In fact, I know the system is going to be perfect, but the batting average of community notes is incredibly good.", "chunk": 13}, {"text": "I've actually frankly yet to see an incorrect note that survived for more than a few hours.", "chunk": 13}], "start": 6293.7, "end": 6297.84}, {"speaker": 0, "transcript": [{"text": "How do you explain why it works?", "chunk": 13}], "start": 6297.84, "end": 6299.44}, {"speaker": 1, "transcript": [{"text": "Yeah, so the magic of community notes is it requires people who have historically disagreed in how they've rated notes.", "chunk": 13}, {"text": "In order to write a note or rate, you have to rate many notes.", "chunk": 13}, {"text": "And so we actually use AI here.", "chunk": 13}, {"text": "So we populate a vector space around how somebody has has rated notes in the past.", "chunk": 13}, {"text": "So it's not as simple as left or right, because there are many more, life is much more complex than left or right.", "chunk": 13}], "start": 6327.2, "end": 6331.78}, {"speaker": 1, "transcript": [{"text": "So there's a bunch of correlations in how you rate community notes posts, community notes.", "chunk": 13}, {"text": "So then in order for a community note to actually be shown, people who historically have disagreed on a subject must agree in order for a note to be shown.", "chunk": 13}, {"text": "That's the essential magic of it.", "chunk": 13}], "start": 6355.48, "end": 6357.26}, {"speaker": 0, "transcript": [{"text": "I mean, but it's fascinating because there's a there's a pool of people that have disagreements and somehow they collaborate through that process of disagreement to come up with context for, I mean, it's fascinating that it works.", "chunk": 13}], "start": 6357.34, "end": 6370.84}, {"speaker": 1, "transcript": [{"text": "Yeah, it kind of makes sense that if people who have put in the past have disagreed agree about something, It's probably true.", "chunk": 13}], "start": 6370.86, "end": 6379.08}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 13}, {"text": "I wonder, is there a possible somehow emergent thing there that could challenge Wikipedia?", "chunk": 13}, {"text": "Wikipedia is a different kind of thing, which is more like permanent articles about things.", "chunk": 13}], "start": 6389.16, "end": 6393.46}, {"speaker": 1, "transcript": [{"text": "Wikipedia is very hierarchical.", "chunk": 13}, {"text": "Whereas Community Notes is inherently not.", "chunk": 13}, {"text": "There is no hierarchy.", "chunk": 13}, {"text": "Like I, and the, the acid test is, I can't change a Community Note if I put a gun to my head.", "chunk": 13}, {"text": "So, and community notes has, all the code is open source, 100%, all the data is open source, 100%.", "chunk": 13}], "start": 6409.34, "end": 6420.8}, {"speaker": 1, "transcript": [{"text": "So you can completely recreate any note in the system independently.", "chunk": 13}, {"text": "So if there was any interference you'd notice immediately.", "chunk": 13}, {"text": "By the", "chunk": 14}], "start": 6431.02, "end": 6431.32}, {"speaker": 0, "transcript": [{"text": "way on the on the topic of Grok it's actually pretty good at criticizing you which is great.", "chunk": 14}, {"text": "Okay.", "chunk": 14}], "start": 6436.42, "end": 6436.92}, {"speaker": 1, "transcript": [{"text": "I", "chunk": 14}], "start": 6436.98, "end": 6437.12}, {"speaker": 0, "transcript": [{"text": "asked what does Elon Musk been wrong about?", "chunk": 14}, {"text": "I just it's actually...", "chunk": 14}], "start": 6440.02, "end": 6441.2}, {"speaker": 1, "transcript": [{"text": "Yeah what does it say?", "chunk": 14}], "start": 6441.48, "end": 6442.96}, {"speaker": 0, "transcript": [{"text": "So it says mostly lists rigorously all the times you predicted, like promised when something will be released.", "chunk": 14}, {"text": "And it wasn't released.", "chunk": 14}], "start": 6451.54, "end": 6452.48}, {"speaker": 1, "transcript": [{"text": "Promise is a strong word.", "chunk": 14}], "start": 6452.48, "end": 6453.26}, {"speaker": 0, "transcript": [{"text": "Okay, predicted.", "chunk": 14}, {"text": "But the opener is really nice.", "chunk": 14}, {"text": "Elon Musk, the man who has been wrong about more things than a wrong meter in a wrong factory.", "chunk": 14}, {"text": "And then it goes on to list.", "chunk": 14}], "start": 6463.42, "end": 6465.06}, {"speaker": 1, "transcript": [{"text": "That's pretty funny.", "chunk": 14}, {"text": "Can I see it?", "chunk": 14}, {"text": "I'm like, I haven't seen this before.", "chunk": 14}], "start": 6466.78, "end": 6467.8}, {"speaker": 0, "transcript": [{"text": "This is cool.", "chunk": 14}, {"text": "Oh, sure.", "chunk": 14}, {"text": "I mean, what has Elon Musk been wrong about?", "chunk": 14}, {"text": "Elon Musk has been wrong about.", "chunk": 14}], "start": 6472.28, "end": 6475.48}, {"speaker": 1, "transcript": [{"text": "Well, where", "chunk": 14}], "start": 6477.0, "end": 6477.34}, {"speaker": 0, "transcript": [{"text": "do I begin?", "chunk": 14}, {"text": "I guess this is new.", "chunk": 14}, {"text": "Elon Musk has made quite a few blunders in his time and I'm not just talking about his dance moves at the Tesla Cyber Rodeo.", "chunk": 14}, {"text": "First off, let's talk about the infamous funding secured tweet.", "chunk": 14}, {"text": "This is actually different than what it gave me before, which is a bullet point list.", "chunk": 14}], "start": 6489.56, "end": 6493.14}, {"speaker": 0, "transcript": [{"text": "Here's more narrative structure.", "chunk": 14}, {"text": "Cyber truck unveiling where he supposedly unbreakable windows.", "chunk": 14}], "start": 6497.32, "end": 6500.06}, {"speaker": 1, "transcript": [{"text": "Not correct.", "chunk": 14}, {"text": "Which part?", "chunk": 14}, {"text": "Well, the first part, I did actually have the funding secured.", "chunk": 14}, {"text": "And there was a big trial in San Francisco, a big civil trial.", "chunk": 14}, {"text": "And the jury found me not guilty.", "chunk": 14}], "start": 6514.58, "end": 6516.64}, {"speaker": 1, "transcript": [{"text": "Unanimous binding of a San Francisco jury.", "chunk": 14}, {"text": "And here it's kind of implying that it was not in fact secured.", "chunk": 14}, {"text": "I think it was taking things from the press.", "chunk": 14}, {"text": "Yeah, that is not correct.", "chunk": 14}, {"text": "The reason I agreed to the fine for the SEC is not because the SEC was correct.", "chunk": 14}], "start": 6528.78, "end": 6533.84}, {"speaker": 1, "transcript": [{"text": "That was extremely bad behavior by the SEC, corruption, frankly.", "chunk": 14}, {"text": "But if I did not agree to pay the fine, Tesla would have gone bankrupt immediately.", "chunk": 14}, {"text": "So I was told by our CFO that the banks would immediately suspend our lines of credit.", "chunk": 14}, {"text": "And if they suspend our lines of credit at that time, we would have gone bankrupt instantly.", "chunk": 14}, {"text": "So there would never have been an opportunity for a trial because it would be dead.", "chunk": 14}], "start": 6560.38, "end": 6563.5}, {"speaker": 1, "transcript": [{"text": "So really, this is like someone holding a gun to your kid's head and saying, pay $20 million and admit to, this is like hostage negotiation.", "chunk": 14}], "start": 6563.94, "end": 6572.86}, {"speaker": 0, "transcript": [{"text": "Was that story fully told?", "chunk": 14}, {"text": "I mean, SEC in its best form could be a force for good.", "chunk": 14}], "start": 6578.0, "end": 6582.08}, {"speaker": 1, "transcript": [{"text": "It should be, but not once did the SEC go after any of the hedge funds who were nonstop shorting and distorting Tesla.", "chunk": 14}, {"text": "Not once.", "chunk": 14}, {"text": "The hedge funds would lie flat out on TV for their own gain at the expense of retail investors.", "chunk": 14}, {"text": "Not once, literally a thousand times, not once did the SEC pursue them.", "chunk": 14}], "start": 6600.48, "end": 6605.26}, {"speaker": 0, "transcript": [{"text": "How do you explain this failure?", "chunk": 14}, {"text": "The incentive", "chunk": 14}], "start": 6608.34, "end": 6608.94}, {"speaker": 1, "transcript": [{"text": "structure is messed up because the lawyers at the SEC are not paid well.", "chunk": 14}, {"text": "It's a fairly low paying job.", "chunk": 14}, {"text": "But what they're looking for is a trophy.", "chunk": 14}, {"text": "From the SEC, they're looking for something they put on, basically they're linked in.", "chunk": 14}, {"text": "From that, they can get a job at a high paying law firm.", "chunk": 14}], "start": 6626.98, "end": 6630.16}, {"speaker": 1, "transcript": [{"text": "That's exactly what the lawyer here did.", "chunk": 14}, {"text": "And the reason they don't attack the hedge funds is because those hedge funds employ those law firms.", "chunk": 14}, {"text": "And they know if they attack the hedge funds, They're affecting their future career prospects.", "chunk": 14}, {"text": "So they sell small investors down the river For their own career That's what actually happens regulatory capture Yeah, not good So the only reason I accepted the thing, technically was a not an admission, it's neither admit nor deny guilt.", "chunk": 14}, {"text": "But the only reason I agreed to that at all was because I was told Tesla would be bankrupt otherwise.", "chunk": 14}], "start": 6672.98, "end": 6679.18}, {"speaker": 1, "transcript": [{"text": "So if there was an SEC investigation like this, banks would suspend funding, we're bankrupt immediately at the time.", "chunk": 15}, {"text": "Now we're in a much stronger position.", "chunk": 15}], "start": 6687.54, "end": 6689.74}, {"speaker": 0, "transcript": [{"text": "Take that, Grok.", "chunk": 15}], "start": 6690.54, "end": 6691.4}, {"speaker": 1, "transcript": [{"text": "Yes.", "chunk": 15}, {"text": "Unfortunately, grok is Taking too much from the conventional media Also that guy was not a cave diver oh", "chunk": 15}], "start": 6692.58, "end": 6701.34}, {"speaker": 0, "transcript": [{"text": "there's a There's a time where Elon called the British cave diver a quote, pedo guy after the diver criticized Musk Plant to rescue a group of boys trapped in a Thai cave.", "chunk": 15}, {"text": "That little outburst earned him another lawsuit and he had to apologize and pay a settlement.", "chunk": 15}], "start": 6715.64, "end": 6720.5}, {"speaker": 1, "transcript": [{"text": "That's false, There was no settlement.", "chunk": 15}, {"text": "There was a court case which the guy who was not a cave diver and played, was not part of the rescue team, filed a lawsuit against me and lost and he received nothing.", "chunk": 15}, {"text": "So in this case, it is wrong.", "chunk": 15}, {"text": "It is also, I guess, taken from the conventional media.", "chunk": 15}], "start": 6740.14, "end": 6742.96}, {"speaker": 0, "transcript": [{"text": "Actually, there's an interesting question here.", "chunk": 15}], "start": 6742.96, "end": 6744.94}, {"speaker": 1, "transcript": [{"text": "These are public court cases.", "chunk": 15}, {"text": "Both the SEC civil case where the civil complaints on the SEC guys lost unanimous jury verdict in San Francisco.", "chunk": 15}, {"text": "They picked San Francisco because they thought it was the place I was most likely to lose and a unanimous verdict in my favor.", "chunk": 15}, {"text": "The LA trial was also, they picked that venue because I thought I was most likely to lose.", "chunk": 15}, {"text": "Unanimous verdict in my favor.", "chunk": 15}], "start": 6772.7, "end": 6774.54}, {"speaker": 1, "transcript": [{"text": "Both cases I won.", "chunk": 15}], "start": 6775.98, "end": 6777.24}, {"speaker": 0, "transcript": [{"text": "Yeah.", "chunk": 15}, {"text": "I mean, There's an interesting question here is that there seems to be a lot more clicks if a journalistic organization writes a negative article about you Elon Musk.", "chunk": 15}, {"text": "That's like 1 of the best ways to get clicks.", "chunk": 15}, {"text": "So how do you, if you're training Grok, not train on articles that have like, the misaligned incentives?", "chunk": 15}], "start": 6796.08, "end": 6805.74}, {"speaker": 1, "transcript": [{"text": "We need to add the training set of the actual legal decisions.", "chunk": 15}, {"text": "So that is a note, this is actually helpful, because if you actually read the court...", "chunk": 15}, {"text": "Which are public.", "chunk": 15}, {"text": "Which are public, the court conclusions, they're completely the opposite of what the media wrote.", "chunk": 15}], "start": 6821.0, "end": 6826.3}, {"speaker": 0, "transcript": [{"text": "So always striving for like the ground truth.", "chunk": 15}], "start": 6826.82, "end": 6829.32}, {"speaker": 1, "transcript": [{"text": "Yeah.", "chunk": 15}, {"text": "What did the judge actually write?", "chunk": 15}, {"text": "What did the jury and the judge actually conclude?", "chunk": 15}, {"text": "And in both cases, they found me innocent.", "chunk": 15}, {"text": "And like That's after the jury shot for trying to find the venue where I'm most likely to lose.", "chunk": 15}], "start": 6839.62, "end": 6844.74}, {"speaker": 1, "transcript": [{"text": "Now, I mean, obviously it can be a much better critique than this.", "chunk": 15}, {"text": "I mean, I've been far too optimistic about autopilot.", "chunk": 15}], "start": 6851.2, "end": 6855.26}, {"speaker": 0, "transcript": [{"text": "That was the critique I got, by the way, was more about that, which is it broke down a nice bullet point list for each of your companies the set of predictions that you made when it will deliver when you be able to solve for example self-driving and it gives you like a list and it was kind of compelling and the basic takeaways like you're often too optimistic about how long it takes to get something done.", "chunk": 15}], "start": 6855.92, "end": 6878.22}, {"speaker": 1, "transcript": [{"text": "Yeah, I mean, I would say that I'm pathologically optimistic on schedule.", "chunk": 15}, {"text": "This is true, but while I am sometimes late, I always deliver in the end.", "chunk": 15}], "start": 6882.54, "end": 6887.7}, {"speaker": 0, "transcript": [{"text": "Except with Uber Lilith, no.", "chunk": 15}, {"text": "We'll see.", "chunk": 15}, {"text": "Okay, is there, over the past year or so, since purchasing X, you've become more political.", "chunk": 15}, {"text": "Is there a part of you that regrets that?", "chunk": 15}, {"text": "Have I?", "chunk": 15}], "start": 6903.66, "end": 6904.34}, {"speaker": 0, "transcript": [{"text": "In this battle to sort of counter way the woke that comes from San Francisco.", "chunk": 15}], "start": 6904.66, "end": 6913.52}, {"speaker": 1, "transcript": [{"text": "Yeah, I guess if you consider fighting the woke mind virus which I consider to be a civilizational threat, to be political then yet.", "chunk": 15}], "start": 6913.52, "end": 6919.26}, {"speaker": 0, "transcript": [{"text": "So basically going into the battleground of politics.", "chunk": 15}, {"text": "Is there a party that would either address that?", "chunk": 15}], "start": 6924.72, "end": 6926.08}, {"speaker": 1, "transcript": [{"text": "Yes, I don't know if this is necessarily sort of 1 candidate or another candidate, but it's...", "chunk": 15}, {"text": "I'm generally against things that are anti-meritocratic or where there's an attempt to suppress discussion, where even discussing a topic is not allowed.", "chunk": 15}, {"text": "The woke mind virus is communism rebranded.", "chunk": 15}], "start": 6947.38, "end": 6949.44}, {"speaker": 0, "transcript": [{"text": "I mean, that said, because of that battle against the woke mind virus, you're perceived as being right wing.", "chunk": 15}], "start": 6951.18, "end": 6957.0}, {"speaker": 1, "transcript": [{"text": "If the woke is left, then I suppose that would be true.", "chunk": 15}, {"text": "But I'm not sure, I think there are aspects of the left that are good.", "chunk": 15}, {"text": "I mean, if you're in favor of the environment, or if you want to have a positive future for humanity, if you believe in empathy for your fellow human beings, being kind and not cruel, whatever those values are.", "chunk": 15}, {"text": "You said that you were previously left or center left.", "chunk": 15}, {"text": "What would you", "chunk": 15}], "start": 6985.94, "end": 6986.38}, {"speaker": 0, "transcript": [{"text": "like to see in order for you to be voting for Democrats again?", "chunk": 15}], "start": 6986.38, "end": 6989.84}, {"speaker": 1, "transcript": [{"text": "No, I would say that I would be probably left of center on social issues, probably a little bit right of center on economic issues.", "chunk": 15}], "start": 6989.92, "end": 6999.44}, {"speaker": 0, "transcript": [{"text": "And that still holds true.", "chunk": 15}], "start": 7000.16, "end": 7001.44}, {"speaker": 1, "transcript": [{"text": "Yes, but I think that's probably half the country.", "chunk": 15}, {"text": "Maybe more.", "chunk": 15}, {"text": "Maybe more.", "chunk": 15}], "start": 7006.46, "end": 7007.0}, {"speaker": 0, "transcript": [{"text": "Are you and AOC secretly friends?", "chunk": 15}, {"text": "Or bigger question, do you wish you and her and just people in general of all political persuasions would talk more and with empathy and maybe have a little bit more fun and good vibes and humor on online?", "chunk": 15}], "start": 7010.04, "end": 7023.28}, {"speaker": 1, "transcript": [{"text": "I'm always in favor of humor.", "chunk": 15}, {"text": "That's why we have a funny mode.", "chunk": 15}], "start": 7026.66, "end": 7027.98}, {"speaker": 0, "transcript": [{"text": "But good vibes, camaraderie humor, you know, like friendship.", "chunk": 15}], "start": 7028.34, "end": 7033.9}, {"speaker": 1, "transcript": [{"text": "Yeah, well, I don't know AOCF.", "chunk": 15}, {"text": "I've only been at 1, I was at the MetWall when she attended.", "chunk": 15}, {"text": "And she was wearing this dress, but I can only see 1 side of it, so it looked like, eat the itch, but I don't know.", "chunk": 15}, {"text": "What the", "chunk": 15}], "start": 7055.1, "end": 7055.3}, {"speaker": 0, "transcript": [{"text": "rest of it said?", "chunk": 15}, {"text": "Yeah, I'm not sure.", "chunk": 15}], "start": 7056.24, "end": 7057.76}, {"speaker": 1, "transcript": [{"text": "Sorry about the itch, eat the itch.", "chunk": 15}, {"text": "I think", "chunk": 15}], "start": 7061.48, "end": 7061.82}, {"speaker": 0, "transcript": [{"text": "we should have a language model complete What are the possible ways to complete that sentence?", "chunk": 15}, {"text": "And so I guess that didn't work out well.", "chunk": 15}], "start": 7068.74, "end": 7071.9}, {"speaker": 1, "transcript": [{"text": "Well, there's still hope.", "chunk": 15}, {"text": "I root for friendship.", "chunk": 16}, {"text": "Sure, sounds good.", "chunk": 16}, {"text": "More characteristic.", "chunk": 16}], "start": 7076.42, "end": 7077.1}, {"speaker": 0, "transcript": [{"text": "You're 1 of, if not the most famous, wealthy and powerful people in the world.", "chunk": 16}, {"text": "In your position, it's difficult to find people you can trust.", "chunk": 16}], "start": 7082.62, "end": 7085.26}, {"speaker": 1, "transcript": [{"text": "Trust no 1, not even yourself not trusting yourself.", "chunk": 16}, {"text": "Okay, well that's,", "chunk": 16}], "start": 7087.34, "end": 7088.24}, {"speaker": 0, "transcript": [{"text": "you're saying that jokingly.", "chunk": 16}, {"text": "But is there some aspect- Trust", "chunk": 16}], "start": 7090.6, "end": 7091.6}, {"speaker": 1, "transcript": [{"text": "no 1, not even no 1.", "chunk": 16}], "start": 7091.6, "end": 7092.84}, {"speaker": 0, "transcript": [{"text": "I'm gonna need an hour just to think about that.", "chunk": 16}, {"text": "And maybe some drugs.", "chunk": 16}, {"text": "And maybe grok that.", "chunk": 16}, {"text": "I mean, is there some aspect of that when just existing in a world where everybody wants something from you?", "chunk": 16}, {"text": "How hard is it to exist in that world?", "chunk": 16}], "start": 7106.06, "end": 7108.1}, {"speaker": 1, "transcript": [{"text": "I'll survive.", "chunk": 16}, {"text": "There's a", "chunk": 16}], "start": 7110.62, "end": 7111.0}, {"speaker": 0, "transcript": [{"text": "song like that too.", "chunk": 16}], "start": 7111.0, "end": 7112.2}, {"speaker": 1, "transcript": [{"text": "I will survive.", "chunk": 16}], "start": 7112.2, "end": 7112.86}, {"speaker": 0, "transcript": [{"text": "Were you petrified at first?", "chunk": 16}, {"text": "Okay, I forget the rest of the lyrics.", "chunk": 16}, {"text": "But is there, you don't struggle with this?", "chunk": 16}, {"text": "I mean, I know you survive, but like there's ways.", "chunk": 16}, {"text": "Petrify is", "chunk": 16}], "start": 7124.24, "end": 7124.74}, {"speaker": 1, "transcript": [{"text": "a spell in the druid tree.", "chunk": 16}, {"text": "What does it do?", "chunk": 16}, {"text": "Petrify.", "chunk": 16}, {"text": "It turns the monsters into stone.", "chunk": 16}], "start": 7132.8, "end": 7134.52}, {"speaker": 0, "transcript": [{"text": "Oh, like literally?", "chunk": 16}, {"text": "Yeah,", "chunk": 16}], "start": 7136.68, "end": 7136.74}, {"speaker": 1, "transcript": [{"text": "for like 6 seconds.", "chunk": 16}], "start": 7136.74, "end": 7138.04}, {"speaker": 0, "transcript": [{"text": "Oh, the seconds.", "chunk": 16}], "start": 7138.16, "end": 7138.98}, {"speaker": 1, "transcript": [{"text": "There's so much math in", "chunk": 16}], "start": 7138.98, "end": 7140.06}, {"speaker": 0, "transcript": [{"text": "Diablo that breaks my brain.", "chunk": 16}], "start": 7140.06, "end": 7141.86}, {"speaker": 1, "transcript": [{"text": "It's like math nonstop.", "chunk": 16}, {"text": "I", "chunk": 16}], "start": 7144.54, "end": 7144.62}, {"speaker": 0, "transcript": [{"text": "mean, really you're like laughing at it, but you don't, it can put a huge amount of tension on a mind.", "chunk": 16}], "start": 7144.62, "end": 7151.78}, {"speaker": 1, "transcript": [{"text": "Yes, it can be definitely stressful at times.", "chunk": 16}, {"text": "Well,", "chunk": 16}], "start": 7155.01, "end": 7155.51}, {"speaker": 0, "transcript": [{"text": "how do you know who you can trust in work and personal life?", "chunk": 16}], "start": 7155.86, "end": 7159.92}, {"speaker": 1, "transcript": [{"text": "I mean I guess you look at somebody's track record over time and if they've got a you know I guess you kind of use your neural net to assess you know someone.", "chunk": 16}], "start": 7159.92, "end": 7170.76}, {"speaker": 0, "transcript": [{"text": "Neural nets don't feel pain.", "chunk": 16}, {"text": "Your neural net has consciousness.", "chunk": 16}, {"text": "It might feel pain when people betray you It can make I'm you know", "chunk": 16}], "start": 7175.22, "end": 7180.44}, {"speaker": 1, "transcript": [{"text": "to be frank, I mean I've almost never been betrayed Very very rare so you know for what I", "chunk": 16}], "start": 7180.44, "end": 7190.18}, {"speaker": 0, "transcript": [{"text": "guess common be good to people, and they'll be good to you.", "chunk": 16}], "start": 7190.18, "end": 7193.36}, {"speaker": 1, "transcript": [{"text": "Yeah, karma's real.", "chunk": 16}], "start": 7193.38, "end": 7194.44}, {"speaker": 0, "transcript": [{"text": "Are there people you trust?", "chunk": 16}, {"text": "Let me edit that question.", "chunk": 16}, {"text": "Are there people close to you that call you out on your bullshit?", "chunk": 16}], "start": 7199.98, "end": 7204.08}, {"speaker": 1, "transcript": [{"text": "Well the X platform is very helpful for that.", "chunk": 16}, {"text": "If you're looking for critical feedback.", "chunk": 16}, {"text": "Can", "chunk": 16}], "start": 7211.1104, "end": 7211.6104}, {"speaker": 0, "transcript": [{"text": "it push you into the extremes more?", "chunk": 16}, {"text": "The extremes of thought make you cynical about human nature in general?", "chunk": 16}], "start": 7214.84, "end": 7217.82}, {"speaker": 1, "transcript": [{"text": "I don't think I will be cynical.", "chunk": 16}, {"text": "In fact, I think, you know, I, my feeling is that 1 should be, you know, Never trust a cynic.", "chunk": 16}, {"text": "The reason is that cynics excuse their own bad behavior by saying everyone does it because they're cynical.", "chunk": 16}, {"text": "So I always be, It's a red flag if someone's a cynic, a true cynic.", "chunk": 16}], "start": 7244.6, "end": 7248.58}, {"speaker": 0, "transcript": [{"text": "Yeah, there's a degree of projection there that's always fun to watch from the outside and enjoy the hypocrisy.", "chunk": 16}], "start": 7249.18, "end": 7255.32}, {"speaker": 1, "transcript": [{"text": "But this is an important point that I think people who are listening should bear in mind, if somebody is cynical, meaning that they see bad behavior in everyone, it's easy for them to excuse their own bad behavior by saying that, well, everyone does it.", "chunk": 16}, {"text": "That's not true.", "chunk": 16}, {"text": "Most people are kind of medium good.", "chunk": 16}], "start": 7280.04, "end": 7282.06}, {"speaker": 0, "transcript": [{"text": "I do wish the people on X would be better at seeing the good in other people's behavior.", "chunk": 16}, {"text": "There seems to be a kind of weight towards seeing the negative.", "chunk": 16}, {"text": "Somehow the negative is sexier.", "chunk": 16}, {"text": "Interpreting the negative is sexier, more viral.", "chunk": 16}, {"text": "I don't know what that is exactly about human nature.", "chunk": 16}], "start": 7301.36, "end": 7303.46}, {"speaker": 1, "transcript": [{"text": "I mean, I find the X platform to be less negative than the legacy media, you know?", "chunk": 16}, {"text": "I mean, if you read sort of conventional newspapers, just, it makes you sad, frankly.", "chunk": 16}, {"text": "Whereas, I'd say on the X platform, I mean, I really get more laughs per day on X than everything else combined from humans.", "chunk": 16}], "start": 7318.68, "end": 7328.36}, {"speaker": 0, "transcript": [{"text": "Laughs is 1 thing, laughs is, it overlaps, but it's not necessarily perfectly overlapping with like good vibes and support, like celebrating others, for example, Not in a stupid, shallow, naive way, but in an awesome way.", "chunk": 16}, {"text": "Like, oh, something awesome happened and you celebrate them for it.", "chunk": 16}, {"text": "It feels that that is outweighed by shitting on other people.", "chunk": 16}, {"text": "Now, it's better than mainstream media, but it's still...", "chunk": 16}], "start": 7354.84, "end": 7358.1}, {"speaker": 1, "transcript": [{"text": "Yeah, mainstream media is almost relatively negative about everything.", "chunk": 16}, {"text": "It's, I mean, really the conventional news tries to answer the question, what is the worst thing that happened on Earth today?", "chunk": 16}, {"text": "And it's a big world.", "chunk": 16}, {"text": "So on any given day, something bad has happened.", "chunk": 16}], "start": 7370.46, "end": 7373.0}, {"speaker": 0, "transcript": [{"text": "And a generalization of that, what is the worst perspective I can take on a thing that happened?", "chunk": 16}], "start": 7374.08, "end": 7378.46}, {"speaker": 1, "transcript": [{"text": "So...", "chunk": 16}, {"text": "Yeah.", "chunk": 16}, {"text": "I don't know.", "chunk": 16}, {"text": "There's just a strong negative bias in the news.", "chunk": 16}, {"text": "I mean, I think there's a possible explanation for this is evolutionary.", "chunk": 16}], "start": 7385.66, "end": 7389.42}, {"speaker": 1, "transcript": [{"text": "Where, you know, bad news historically would be potentially fatal.", "chunk": 16}, {"text": "Like, there's a lion over there or there's some other tribe that wants to kill you.", "chunk": 16}, {"text": "Good news, you know, like we found a patch of berries is nice to have, but not essential.", "chunk": 16}], "start": 7402.18, "end": 7407.34}, {"speaker": 0, "transcript": [{"text": "So, our old friend, Tesla Autopilot, and it's probably 1 of the most intelligent real-world AI systems in the world.", "chunk": 17}, {"text": "Right, you followed it from the beginning.", "chunk": 17}, {"text": "Yeah, it was 1 of the most incredible robots in the world and it continues to be.", "chunk": 17}, {"text": "Yeah.", "chunk": 17}, {"text": "And it was really exciting.", "chunk": 17}], "start": 7424.68, "end": 7425.08}, {"speaker": 0, "transcript": [{"text": "And it was super exciting when it generalized, became more than a robot on 4 wheels, but a real world AI system that perceives the world.", "chunk": 17}, {"text": "Yeah.", "chunk": 17}, {"text": "And can have potentially different embodiments.", "chunk": 17}], "start": 7437.98, "end": 7440.34}, {"speaker": 1, "transcript": [{"text": "Well, I mean, the really wild thing about the end-to-end training is that it like it learns to read, like you can read signs, but we never taught it to read.", "chunk": 17}, {"text": "So yeah, we never taught it what a car was or what a person was or a bicycle cyclist It learned what What all those things are what all the objects are on the road?", "chunk": 17}, {"text": "From video just from watching video just like humans.", "chunk": 17}, {"text": "I mean humans are photons and control controls out Like the vast majority of information reaching our brain is from our eyes.", "chunk": 17}, {"text": "And you say, well, what's the output?", "chunk": 17}], "start": 7483.78, "end": 7485.06}, {"speaker": 1, "transcript": [{"text": "The output is our motor signals to our fingers and mouth in order to communicate.", "chunk": 17}, {"text": "Photons in, controls out.", "chunk": 17}, {"text": "The same is true of the car.", "chunk": 17}], "start": 7497.18, "end": 7498.76}, {"speaker": 0, "transcript": [{"text": "But by looking at the sequence of images, it's, you've agreed with Ilya Suskova recently, where he talked about LLM forming a world model and basically language is a projection of that world model onto the sequence of Letters and you're saying- It finds", "chunk": 17}], "start": 7500.72, "end": 7518.12}, {"speaker": 1, "transcript": [{"text": "order in these things.", "chunk": 17}, {"text": "It finds correlative clusters.", "chunk": 17}], "start": 7521.48, "end": 7525.06}, {"speaker": 0, "transcript": [{"text": "And so doing is like understanding something deep about the world.", "chunk": 17}, {"text": "Yeah.", "chunk": 17}], "start": 7530.38, "end": 7530.88}, {"speaker": 1, "transcript": [{"text": "Which is like, it's beautiful.", "chunk": 17}, {"text": "That's how our brain works.", "chunk": 17}, {"text": "Yeah, but it's beautiful.", "chunk": 17}, {"text": "Controls out.", "chunk": 17}, {"text": "Neural", "chunk": 17}], "start": 7540.44, "end": 7540.72}, {"speaker": 0, "transcript": [{"text": "nets are able to understand that deep meaning in the world.", "chunk": 17}, {"text": "And so the question is how far can it go?", "chunk": 17}, {"text": "And it does seem everybody's excited about LLMs.", "chunk": 17}, {"text": "So in the space of self-supervised learning, the space of text, it seems like there's a deep similarity between that and what Tesla Autopilot is doing.", "chunk": 17}, {"text": "Is it to you basically the same?", "chunk": 17}], "start": 7563.9, "end": 7565.8}, {"speaker": 0, "transcript": [{"text": "But different data?", "chunk": 17}, {"text": "They are converging.", "chunk": 17}], "start": 7567.02, "end": 7567.74}, {"speaker": 1, "transcript": [{"text": "They are converging.", "chunk": 17}, {"text": "I wonder", "chunk": 17}], "start": 7570.3, "end": 7570.64}, {"speaker": 0, "transcript": [{"text": "who gets there faster, having a deep understanding of the world.", "chunk": 17}, {"text": "Or they just will naturally converge?", "chunk": 17}], "start": 7576.36, "end": 7578.14}, {"speaker": 1, "transcript": [{"text": "They're both headed towards AGI.", "chunk": 17}, {"text": "The Tesla approach is much more computer efficient.", "chunk": 17}, {"text": "It had to be because we were constrained on this.", "chunk": 17}, {"text": "You know, we only have 100 watts and it's 8 computer, 144 trillion operations per second, which sounds like a lot, but it's kind of small potatoes these days.", "chunk": 17}, {"text": "That it ate, but it's understanding the world at a date.", "chunk": 17}], "start": 7608.18, "end": 7610.34}, {"speaker": 1, "transcript": [{"text": "So I turn for 2 6 values.", "chunk": 17}], "start": 7612.26, "end": 7613.9}, {"speaker": 0, "transcript": [{"text": "But there the path to AGI might have much more significant impact because it's understanding.", "chunk": 17}, {"text": "It will faster understand the real world than will LLMs and They're bored for be able to integrate with with the real humans in the real world faster", "chunk": 17}], "start": 7622.54, "end": 7631.7}, {"speaker": 1, "transcript": [{"text": "They're both Going to understand the world, but I think Tesla's approach is fundamentally more compute efficient.", "chunk": 17}, {"text": "It had to be.", "chunk": 17}, {"text": "There was no choice.", "chunk": 17}, {"text": "Our brain is very compute efficient, very energy efficient.", "chunk": 17}, {"text": "So think of like, what is our brain able to do?", "chunk": 17}], "start": 7646.84, "end": 7649.84}, {"speaker": 1, "transcript": [{"text": "There's only about 10 watts of higher brain function, not counting stuff that's just used to control our body.", "chunk": 17}, {"text": "The thinking part of our brain is less than 10 watts.", "chunk": 17}, {"text": "And those 10 watts can still produce a much better novel than a 10 megawatt GPU cluster.", "chunk": 17}, {"text": "So there's a 6 order of magnitude difference there.", "chunk": 17}, {"text": "I mean, the AI has thus far gotten to where it is via brute force, just throwing massive amounts of compute and massive amounts of power at it.", "chunk": 17}], "start": 7675.8, "end": 7687.36}, {"speaker": 1, "transcript": [{"text": "So this is not where it will end up.", "chunk": 17}, {"text": "You know, in general, with any given technology, first try to make it work and then you make it efficient.", "chunk": 17}, {"text": "So I think we'll find over time that these models get smaller, are able to produce sensible output with far less compute, far less power.", "chunk": 17}, {"text": "Tesla is arguably ahead of the game on that front because we've just been forced to try to understand the world with a hundred watts of compute.", "chunk": 17}, {"text": "And there are a bunch of sort of fundamental functions that we kind of forgot to include, so we have to run them in a bunch of things in emulation.", "chunk": 17}], "start": 7731.28, "end": 7738.04}, {"speaker": 1, "transcript": [{"text": "We fixed, fixed a bunch of those with hardware 4 and then hardware 5 will be even better.", "chunk": 17}, {"text": "But it does appear at this point that the car will be able to drive better than a human, even with hardware 3 and a hundred watts of power.", "chunk": 17}, {"text": "And really, if we really optimize it, it could be probably less than 50 watts.", "chunk": 17}, {"text": "What have", "chunk": 17}], "start": 7766.38, "end": 7766.76}, {"speaker": 0, "transcript": [{"text": "you learned about developing Optimus, about applying, integrating this kind of real world AI into the space of robotic manipulation, just humanoid robotics.", "chunk": 17}, {"text": "What are some interesting tiny or big things you've understood?", "chunk": 17}], "start": 7782.08, "end": 7786.44}, {"speaker": 1, "transcript": [{"text": "I was surprised at the fact that we had to develop every part of the robot ourselves.", "chunk": 17}, {"text": "That there were no off the shelf motors, electronics, sensors.", "chunk": 17}, {"text": "Like we had to develop everything.", "chunk": 17}, {"text": "We couldn't actually find a source of electric motors for any amount of money.", "chunk": 17}, {"text": "So it's not", "chunk": 17}], "start": 7811.92, "end": 7812.38}, {"speaker": 0, "transcript": [{"text": "even just efficient and expensive, it's like anything.", "chunk": 17}, {"text": "There's not a...", "chunk": 17}, {"text": "No.", "chunk": 17}, {"text": "The actuators, everything.", "chunk": 17}, {"text": "Everything has to be designed from scratch.", "chunk": 17}], "start": 7819.7, "end": 7822.54}, {"speaker": 1, "transcript": [{"text": "We tried hard to find anything that was, because you think of how many electric motors are made in the world, there's like tens of thousands, hundreds of thousands of electric motor designs.", "chunk": 17}, {"text": "None of them were suitable for a humanoid robot, literally none.", "chunk": 17}, {"text": "So we had to develop our own design, design it specifically for, for what a humanoid robot needs.", "chunk": 17}, {"text": "How", "chunk": 17}], "start": 7851.04, "end": 7851.14}, {"speaker": 0, "transcript": [{"text": "hard was it to design something that can be mass manufactured, could be relatively inexpensive?", "chunk": 17}, {"text": "I mean, if you compare it to Boston Dynamics Atlas, it's a very expensive robot.", "chunk": 17}], "start": 7856.4, "end": 7861.08}, {"speaker": 1, "transcript": [{"text": "It is designed to be manufactured in the same way they would make a car.", "chunk": 17}, {"text": "And I think ultimately we can make Optimus for less than the cost of a car.", "chunk": 17}, {"text": "It should be, because if you look at the mass of the robot, it's much smaller.", "chunk": 17}, {"text": "And the car has many actuators in it.", "chunk": 17}, {"text": "The car has more actuators than the robot.", "chunk": 17}], "start": 7880.58, "end": 7882.4}, {"speaker": 0, "transcript": [{"text": "But there is the actuators are kind of interesting on a humanoid robot with fingers.", "chunk": 17}, {"text": "So Optimus has really nice hands and fingers, you know.", "chunk": 17}, {"text": "Yeah.", "chunk": 17}, {"text": "And they could do some interesting manipulation.", "chunk": 17}, {"text": "So soft touch robotics.", "chunk": 17}], "start": 7896.28, "end": 7897.74}, {"speaker": 0, "transcript": [{"text": "I", "chunk": 17}], "start": 7897.97, "end": 7898.47}, {"speaker": 1, "transcript": [{"text": "mean, 1 of the tests goals I have is can pick up a needle and a thread and thread the needle just by looking.", "chunk": 17}], "start": 7898.7, "end": 7907.04}, {"speaker": 0, "transcript": [{"text": "How far away are we from that?", "chunk": 17}, {"text": "Just by looking, just by looking.", "chunk": 17}], "start": 7909.08, "end": 7910.96}, {"speaker": 1, "transcript": [{"text": "Maybe a year.", "chunk": 17}, {"text": "Although I go back to I'm optimistic on time.", "chunk": 17}, {"text": "The work that we're doing in the car will translate to the robot.", "chunk": 17}, {"text": "The perception or the also the control?", "chunk": 17}], "start": 7918.86, "end": 7921.14}, {"speaker": 0, "transcript": [{"text": "No, the", "chunk": 17}], "start": 7921.64, "end": 7922.02}, {"speaker": 1, "transcript": [{"text": "controls are different, but the video in controls out.", "chunk": 17}, {"text": "The car is a robot on 4 wheels.", "chunk": 17}, {"text": "The optimus is a robot with hands and legs.", "chunk": 17}, {"text": "They're very similar.", "chunk": 17}, {"text": "So the", "chunk": 17}], "start": 7937.26, "end": 7937.6}, {"speaker": 0, "transcript": [{"text": "entire machinery of the learning process and to end is just, you just have a different set of controls.", "chunk": 17}], "start": 7937.6, "end": 7943.12}, {"speaker": 1, "transcript": [{"text": "After this, we'll figure out how to do things by watching videos.", "chunk": 17}], "start": 7943.42, "end": 7946.18}, {"speaker": 0, "transcript": [{"text": "As the saying goes, be kind for everyone you meet is fighting a battle.", "chunk": 17}, {"text": "You know nothing about.", "chunk": 17}, {"text": "Yeah, it's", "chunk": 17}], "start": 7952.9, "end": 7953.26}, {"speaker": 1, "transcript": [{"text": "true.", "chunk": 17}, {"text": "What's", "chunk": 17}], "start": 7953.78, "end": 7954.02}, {"speaker": 0, "transcript": [{"text": "something difficult you're going through that people don't often see?", "chunk": 17}], "start": 7954.02, "end": 7957.0}, {"speaker": 1, "transcript": [{"text": "Trying to feed people.", "chunk": 17}, {"text": "No, I mean, You know, I mean, my mind is a storm.", "chunk": 17}, {"text": "I don't think most people would want to be me.", "chunk": 17}, {"text": "They may think they'd want to be me, but they don't know, they don't understand.", "chunk": 17}], "start": 7976.26, "end": 7979.66}, {"speaker": 0, "transcript": [{"text": "How are you doing?", "chunk": 17}, {"text": "How are you doing?", "chunk": 17}], "start": 7990.836, "end": 7991.56}, {"speaker": 1, "transcript": [{"text": "I'm overall okay.", "chunk": 17}, {"text": "The grand scheme of things I can't complain.", "chunk": 17}, {"text": "You", "chunk": 17}], "start": 8000.94, "end": 8001.06}, {"speaker": 0, "transcript": [{"text": "get lonely?", "chunk": 17}], "start": 8001.06, "end": 8001.8}, {"speaker": 1, "transcript": [{"text": "Sometimes, but I, you know, my kids and friends keep me company.", "chunk": 17}], "start": 8004.06, "end": 8010.18}, {"speaker": 0, "transcript": [{"text": "So not existential.", "chunk": 17}], "start": 8012.68, "end": 8013.84}, {"speaker": 1, "transcript": [{"text": "There are many nights I sleep alone.", "chunk": 17}, {"text": "I don't have to, but I do.", "chunk": 17}], "start": 8018.71, "end": 8024.573}, {"speaker": 0, "transcript": [{"text": "Walter Isaacson in his new biography of you wrote about your difficult childhood.", "chunk": 18}, {"text": "Will you ever find forgiveness in your heart for everything that has happened to you in that period of your life?", "chunk": 18}], "start": 8030.9, "end": 8036.34}, {"speaker": 1, "transcript": [{"text": "What is forgiveness?", "chunk": 18}, {"text": "I do not, at least I don't think I have a resentment.", "chunk": 18}, {"text": "So, nothing to forgive.", "chunk": 18}], "start": 8053.96, "end": 8057.66}, {"speaker": 0, "transcript": [{"text": "You know, forgiveness is difficult for people.", "chunk": 18}, {"text": "It seems like you don't harbor the resentment.", "chunk": 18}], "start": 8063.4, "end": 8066.66}, {"speaker": 1, "transcript": [{"text": "I mean, I try to think about like what is going to affect the future in a good way?", "chunk": 18}, {"text": "And holding onto grudges does not affect the future in a good way.", "chunk": 18}], "start": 8073.98, "end": 8080.12}, {"speaker": 0, "transcript": [{"text": "Your father, a proud father, what have you learned about life from your kids?", "chunk": 18}, {"text": "Those little biological organisms.", "chunk": 18}], "start": 8088.66, "end": 8090.36}, {"speaker": 1, "transcript": [{"text": "I mean, developing AI and watching say a little X grow is fascinating because they, there are far more parallels than I would have expected.", "chunk": 18}, {"text": "I mean, I can see his biological neural net making more and more sense of the world.", "chunk": 18}, {"text": "And I can see the digital neural net making more and more sense of the world at the same time.", "chunk": 18}, {"text": "Do you", "chunk": 18}], "start": 8118.68, "end": 8118.92}, {"speaker": 0, "transcript": [{"text": "see the beauty and magic in both?", "chunk": 18}, {"text": "Yes.", "chunk": 18}], "start": 8121.4, "end": 8121.9}, {"speaker": 1, "transcript": [{"text": "I mean, 1 of the things with kids is that, you kind of see the world anew in their eyes.", "chunk": 18}, {"text": "You know, to them, everything is new and fresh.", "chunk": 18}, {"text": "And then when you see that, they make sure The world is new and fresh.", "chunk": 18}, {"text": "You do too.", "chunk": 18}], "start": 8147.96, "end": 8148.84}, {"speaker": 0, "transcript": [{"text": "Well, Elon, I just want to say thank you for your kindness to me and friendship over the years, for seeing something in a silly kid like me as you've done for many others.", "chunk": 18}, {"text": "And, thank you for having hope for a positive future for humanity and for working your ass off to make it happen.", "chunk": 18}, {"text": "Thank you, Elon.", "chunk": 18}, {"text": "Thanks Lex.", "chunk": 18}], "start": 8171.4, "end": 8172.1}, {"speaker": 1, "transcript": [{"text": "Thank you", "chunk": 18}], "start": 8172.74, "end": 8173.08}, {"speaker": 0, "transcript": [{"text": "for listening to this conversation with Elon Musk.", "chunk": 18}, {"text": "To support this podcast, please check out our sponsors in the description.", "chunk": 18}, {"text": "And now let me leave you with some words that Walter Isaacson wrote about the central philosophy of how Elon approaches difficult problems.", "chunk": 18}, {"text": "The only rules are the ones dictated by the laws of physics.", "chunk": 18}, {"text": "Thank you for listening, and hope to see you next time.", "chunk": 18}], "start": 8194.24, "end": 8197.4}]}